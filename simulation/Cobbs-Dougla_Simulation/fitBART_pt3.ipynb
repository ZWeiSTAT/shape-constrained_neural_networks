{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3dc942-cad4-49a5-abfb-8c2cf4cc8fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘foreach’ was built under R version 4.2.3”\n",
      "Loading required package: iterators\n",
      "\n",
      "Warning message:\n",
      "“package ‘iterators’ was built under R version 4.2.3”\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: micEcon\n",
      "\n",
      "\n",
      "If you have questions, suggestions, or comments regarding one of the 'micEcon' packages, please use a forum or 'tracker' at micEcon's R-Forge site:\n",
      "https://r-forge.r-project.org/projects/micecon/\n",
      "\n",
      "Loading required package: lmtest\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "\n",
      "Please cite the 'frontier' package as:\n",
      "Tim Coelli and Arne Henningsen (2013). frontier: Stochastic Frontier Analysis. R package version 1.1. http://CRAN.R-Project.org/package=frontier.\n",
      "\n",
      "If you have questions, suggestions, or comments regarding the 'frontier' package, please use a forum or 'tracker' at frontier's R-Forge site:\n",
      "https://r-forge.r-project.org/projects/frontier/\n",
      "\n",
      "Loading required package: stats4\n",
      "\n",
      "\n",
      "Attaching package: ‘sn’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    sd\n",
      "\n",
      "\n",
      "Loading required package: mgcv\n",
      "\n",
      "Loading required package: nlme\n",
      "\n",
      "This is mgcv 1.8-41. For overview type 'help(\"mgcv-package\")'.\n",
      "\n",
      "Loading required package: np\n",
      "\n",
      "Warning message:\n",
      "“package ‘np’ was built under R version 4.2.3”\n",
      "Nonparametric Kernel Methods for Mixed Datatypes (version 0.60-17)\n",
      "[vignette(\"np_faq\",package=\"np\") provides answers to frequently asked questions]\n",
      "[vignette(\"np\",package=\"np\") an overview]\n",
      "[vignette(\"entropy_np\",package=\"np\") an overview of entropy-based methods]\n",
      "\n",
      "Loading required package: gamlss\n",
      "\n",
      "Loading required package: splines\n",
      "\n",
      "Loading required package: gamlss.data\n",
      "\n",
      "\n",
      "Attaching package: ‘gamlss.data’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:datasets’:\n",
      "\n",
      "    sleep\n",
      "\n",
      "\n",
      "Loading required package: gamlss.dist\n",
      "\n",
      " **********   GAMLSS Version 5.4-3  ********** \n",
      "\n",
      "For more on GAMLSS look at https://www.gamlss.com/\n",
      "\n",
      "Type gamlssNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rm(list = ls())\n",
    "#setwd('/Users/zhengwei/Desktop/OneDrive - Texas A&M University-Corpus Christi/Research/Huiyan_Sang/DecisionTree/MyPackage/sim1_lin')\n",
    "#setwd(\"/Users/zhengwei/OneDrive - Texas A&M University-Corpus Christi/Research/Huiyan_Sang/DecisionTree/MyPackage/sim1_lin\")\n",
    "\n",
    "library(foreach)\n",
    "library(doMC)\n",
    "library(coda)\n",
    "library(MonBartSFM)\n",
    "library(frontier)\n",
    "library(truncnorm)\n",
    "library(sn)\n",
    "library(MASS)\n",
    "library(semsfa)\n",
    "source(\"otherfuns.R\")\n",
    "source(\"Bayes_SFM_NHN_Gibbs.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfa84ef-70e6-43a7-9dc4-a041485f99a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>log_X</th><th scope=col>log_y</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 2.768552</td><td> 0.2527462</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>-2.856968</td><td>-0.6890037</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>-1.137870</td><td> 0.5694323</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 2.452089</td><td> 2.5354790</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>-1.278954</td><td> 1.4797850</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-1.649340</td><td> 0.2519563</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & log\\_X & log\\_y\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 &  2.768552 &  0.2527462\\\\\n",
       "\t2 & -2.856968 & -0.6890037\\\\\n",
       "\t3 & -1.137870 &  0.5694323\\\\\n",
       "\t4 &  2.452089 &  2.5354790\\\\\n",
       "\t5 & -1.278954 &  1.4797850\\\\\n",
       "\t6 & -1.649340 &  0.2519563\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | log_X &lt;dbl&gt; | log_y &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 |  2.768552 |  0.2527462 |\n",
       "| 2 | -2.856968 | -0.6890037 |\n",
       "| 3 | -1.137870 |  0.5694323 |\n",
       "| 4 |  2.452089 |  2.5354790 |\n",
       "| 5 | -1.278954 |  1.4797850 |\n",
       "| 6 | -1.649340 |  0.2519563 |\n",
       "\n"
      ],
      "text/plain": [
       "  log_X     log_y     \n",
       "1  2.768552  0.2527462\n",
       "2 -2.856968 -0.6890037\n",
       "3 -1.137870  0.5694323\n",
       "4  2.452089  2.5354790\n",
       "5 -1.278954  1.4797850\n",
       "6 -1.649340  0.2519563"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set path to your folder\n",
    "path <- \"simulated_data\"\n",
    "\n",
    "# List all CSV files in that folder\n",
    "files <- list.files(path, pattern = \"\\\\.csv$\", full.names = TRUE)\n",
    "\n",
    "# Read each CSV into a list of data.frames\n",
    "simulated_datasets_R <- lapply(files, read.csv)\n",
    "\n",
    "# Access the first dataset\n",
    "head(simulated_datasets_R[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6104df-bd6e-4587-9a42-6a1902d2d3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  21 \n",
      "Cumulative average: iter= 1000 beta0= 0.7431 beta= 0.3018 sigmav= 0.9382 sigmau= 0.2741 \n",
      "Cumulative average: iter= 2000 beta0= 0.7403 beta= 0.3035 sigmav= 0.9339 sigmau= 0.2714 \n",
      "Cumulative average: iter= 3000 beta0= 0.7349 beta= 0.3039 sigmav= 0.9351 sigmau= 0.2634 \n",
      "Cumulative average: iter= 4000 beta0= 0.7332 beta= 0.3039 sigmav= 0.9341 sigmau= 0.2603 \n",
      "Cumulative average: iter= 5000 beta0= 0.7288 beta= 0.3041 sigmav= 0.9345 sigmau= 0.2559 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -2.034476, -0.662066\n",
      "first row: -1.380237, -1.380237\n",
      "second row: 1.912423, 1.912423\n",
      "last row: 0.370349, 0.370349\n",
      "no test observations\n",
      "tau: 0.171872\n",
      "nu: 3.000000\n",
      "lambda: 0.101126\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.871640 ... 2.912404\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -2.034476, -0.662066\n",
      "first row: -1.380237, -1.380237\n",
      "second row: 1.912423, 1.912423\n",
      "last row: 0.370349, 0.370349\n",
      "no test observations\n",
      "tau: 0.171872\n",
      "nu: 3.000000\n",
      "lambda: 0.101126\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.871640 ... 2.912404\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  22 \n",
      "Cumulative average: iter= 1000 beta0= 0.7665 beta= 0.239 sigmav= 0.8141 sigmau= 0.3188 \n",
      "Cumulative average: iter= 2000 beta0= 0.752 beta= 0.2373 sigmav= 0.8154 sigmau= 0.3014 \n",
      "Cumulative average: iter= 3000 beta0= 0.7855 beta= 0.2368 sigmav= 0.807 sigmau= 0.3424 \n",
      "Cumulative average: iter= 4000 beta0= 0.7934 beta= 0.2366 sigmav= 0.8055 sigmau= 0.3517 \n",
      "Cumulative average: iter= 5000 beta0= 0.7778 beta= 0.2366 sigmav= 0.8093 sigmau= 0.3334 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -2.110067, -0.942111\n",
      "first row: -2.966632, -2.966632\n",
      "second row: 0.192287, 0.192287\n",
      "last row: -0.636234, -0.636234\n",
      "no test observations\n",
      "tau: 0.144152\n",
      "nu: 3.000000\n",
      "lambda: 0.051962\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.930053 ... 2.919553\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -2.110067, -0.942111\n",
      "first row: -2.966632, -2.966632\n",
      "second row: 0.192287, 0.192287\n",
      "last row: -0.636234, -0.636234\n",
      "no test observations\n",
      "tau: 0.144152\n",
      "nu: 3.000000\n",
      "lambda: 0.051962\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.930053 ... 2.919553\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  23 \n",
      "Cumulative average: iter= 1000 beta0= 0.8831 beta= 0.2417 sigmav= 0.939 sigmau= 0.3184 \n",
      "Cumulative average: iter= 2000 beta0= 0.9065 beta= 0.2406 sigmav= 0.9322 sigmau= 0.344 \n",
      "Cumulative average: iter= 3000 beta0= 0.8756 beta= 0.2403 sigmav= 0.9379 sigmau= 0.3034 \n",
      "Cumulative average: iter= 4000 beta0= 0.875 beta= 0.2407 sigmav= 0.9387 sigmau= 0.3021 \n",
      "Cumulative average: iter= 5000 beta0= 0.8652 beta= 0.241 sigmav= 0.9402 sigmau= 0.29 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.659257, -1.686612\n",
      "first row: 0.770037, 0.770037\n",
      "second row: -0.204683, -0.204683\n",
      "last row: -1.119545, -1.119545\n",
      "no test observations\n",
      "tau: 0.181604\n",
      "nu: 3.000000\n",
      "lambda: 0.091008\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.911303 ... 2.930717\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.659257, -1.686612\n",
      "first row: 0.770037, 0.770037\n",
      "second row: -0.204683, -0.204683\n",
      "last row: -1.119545, -1.119545\n",
      "no test observations\n",
      "tau: 0.181604\n",
      "nu: 3.000000\n",
      "lambda: 0.091008\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.911303 ... 2.930717\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  24 \n",
      "Cumulative average: iter= 1000 beta0= 0.8062 beta= 0.204 sigmav= 0.9223 sigmau= 0.273 \n",
      "Cumulative average: iter= 2000 beta0= 0.7855 beta= 0.2046 sigmav= 0.9262 sigmau= 0.2502 \n",
      "Cumulative average: iter= 3000 beta0= 0.7893 beta= 0.2049 sigmav= 0.9267 sigmau= 0.2552 \n",
      "Cumulative average: iter= 4000 beta0= 0.7878 beta= 0.2052 sigmav= 0.9264 sigmau= 0.2529 \n",
      "Cumulative average: iter= 5000 beta0= 0.787 beta= 0.2052 sigmav= 0.9263 sigmau= 0.2525 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.521375, -1.733533\n",
      "first row: 1.463339, 1.463339\n",
      "second row: -0.828208, -0.828208\n",
      "last row: -1.654567, -1.654567\n",
      "no test observations\n",
      "tau: 0.149655\n",
      "nu: 3.000000\n",
      "lambda: 0.100850\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.929533 ... 2.927013\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.521375, -1.733533\n",
      "first row: 1.463339, 1.463339\n",
      "second row: -0.828208, -0.828208\n",
      "last row: -1.654567, -1.654567\n",
      "no test observations\n",
      "tau: 0.149655\n",
      "nu: 3.000000\n",
      "lambda: 0.100850\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.929533 ... 2.927013\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  25 \n",
      "Cumulative average: iter= 1000 beta0= 0.6416 beta= 0.1885 sigmav= 0.8536 sigmau= 0.2748 \n",
      "Cumulative average: iter= 2000 beta0= 0.6327 beta= 0.1886 sigmav= 0.8541 sigmau= 0.2624 \n",
      "Cumulative average: iter= 3000 beta0= 0.638 beta= 0.1886 sigmav= 0.854 sigmau= 0.2672 \n",
      "Cumulative average: iter= 4000 beta0= 0.6386 beta= 0.1882 sigmav= 0.8542 sigmau= 0.2676 \n",
      "Cumulative average: iter= 5000 beta0= 0.6381 beta= 0.1881 sigmav= 0.8546 sigmau= 0.2664 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.093313, -0.068426\n",
      "first row: 2.458702, 2.458702\n",
      "second row: 2.005675, 2.005675\n",
      "last row: -2.790149, -2.790149\n",
      "no test observations\n",
      "tau: 0.147858\n",
      "nu: 3.000000\n",
      "lambda: 0.086013\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.895034 ... 2.937855\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.093313, -0.068426\n",
      "first row: 2.458702, 2.458702\n",
      "second row: 2.005675, 2.005675\n",
      "last row: -2.790149, -2.790149\n",
      "no test observations\n",
      "tau: 0.147858\n",
      "nu: 3.000000\n",
      "lambda: 0.086013\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.895034 ... 2.937855\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  26 \n",
      "Cumulative average: iter= 1000 beta0= 0.8378 beta= 0.1396 sigmav= 0.8832 sigmau= 0.2741 \n",
      "Cumulative average: iter= 2000 beta0= 0.8346 beta= 0.138 sigmav= 0.883 sigmau= 0.2719 \n",
      "Cumulative average: iter= 3000 beta0= 0.8315 beta= 0.1376 sigmav= 0.8844 sigmau= 0.2661 \n",
      "Cumulative average: iter= 4000 beta0= 0.832 beta= 0.1375 sigmav= 0.8844 sigmau= 0.2659 \n",
      "Cumulative average: iter= 5000 beta0= 0.8305 beta= 0.1375 sigmav= 0.8842 sigmau= 0.2642 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.295235, 0.273023\n",
      "first row: -1.124006, -1.124006\n",
      "second row: -1.948483, -1.948483\n",
      "last row: -2.394290, -2.394290\n",
      "no test observations\n",
      "tau: 0.156446\n",
      "nu: 3.000000\n",
      "lambda: 0.085967\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.932392 ... 2.769951\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.295235, 0.273023\n",
      "first row: -1.124006, -1.124006\n",
      "second row: -1.948483, -1.948483\n",
      "last row: -2.394290, -2.394290\n",
      "no test observations\n",
      "tau: 0.156446\n",
      "nu: 3.000000\n",
      "lambda: 0.085967\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.932392 ... 2.769951\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  27 \n",
      "Cumulative average: iter= 1000 beta0= 0.7634 beta= 0.2658 sigmav= 0.9681 sigmau= 0.2262 \n",
      "Cumulative average: iter= 2000 beta0= 0.7854 beta= 0.2643 sigmav= 0.9644 sigmau= 0.2568 \n",
      "Cumulative average: iter= 3000 beta0= 0.7931 beta= 0.2644 sigmav= 0.9631 sigmau= 0.267 \n",
      "Cumulative average: iter= 4000 beta0= 0.7943 beta= 0.2647 sigmav= 0.9627 sigmau= 0.2691 \n",
      "Cumulative average: iter= 5000 beta0= 0.8031 beta= 0.2645 sigmav= 0.9616 sigmau= 0.2791 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.687198, 1.042885\n",
      "first row: -1.221680, -1.221680\n",
      "second row: 1.741478, 1.741478\n",
      "last row: 0.492234, 0.492234\n",
      "no test observations\n",
      "tau: 0.186182\n",
      "nu: 3.000000\n",
      "lambda: 0.109368\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.903158 ... 2.931838\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.687198, 1.042885\n",
      "first row: -1.221680, -1.221680\n",
      "second row: 1.741478, 1.741478\n",
      "last row: 0.492234, 0.492234\n",
      "no test observations\n",
      "tau: 0.186182\n",
      "nu: 3.000000\n",
      "lambda: 0.109368\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.903158 ... 2.931838\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  28 \n",
      "Cumulative average: iter= 1000 beta0= 0.7272 beta= 0.207 sigmav= 0.9474 sigmau= 0.288 \n",
      "Cumulative average: iter= 2000 beta0= 0.7375 beta= 0.2072 sigmav= 0.9479 sigmau= 0.3 \n",
      "Cumulative average: iter= 3000 beta0= 0.7364 beta= 0.2081 sigmav= 0.9475 sigmau= 0.2989 \n",
      "Cumulative average: iter= 4000 beta0= 0.7375 beta= 0.2085 sigmav= 0.9466 sigmau= 0.2996 \n",
      "Cumulative average: iter= 5000 beta0= 0.7323 beta= 0.2089 sigmav= 0.9476 sigmau= 0.2919 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.795460, 2.066928\n",
      "first row: 2.342484, 2.342484\n",
      "second row: -1.166586, -1.166586\n",
      "last row: 2.774253, 2.774253\n",
      "no test observations\n",
      "tau: 0.157880\n",
      "nu: 3.000000\n",
      "lambda: 0.106937\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.915270 ... 2.929672\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.795460, 2.066928\n",
      "first row: 2.342484, 2.342484\n",
      "second row: -1.166586, -1.166586\n",
      "last row: 2.774253, 2.774253\n",
      "no test observations\n",
      "tau: 0.157880\n",
      "nu: 3.000000\n",
      "lambda: 0.106937\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.915270 ... 2.929672\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  29 \n",
      "Cumulative average: iter= 1000 beta0= 0.7748 beta= 0.175 sigmav= 0.905 sigmau= 0.245 \n",
      "Cumulative average: iter= 2000 beta0= 0.7789 beta= 0.1744 sigmav= 0.9031 sigmau= 0.2502 \n",
      "Cumulative average: iter= 3000 beta0= 0.7981 beta= 0.1742 sigmav= 0.9005 sigmau= 0.2721 \n",
      "Cumulative average: iter= 4000 beta0= 0.792 beta= 0.1736 sigmav= 0.9016 sigmau= 0.2644 \n",
      "Cumulative average: iter= 5000 beta0= 0.7919 beta= 0.174 sigmav= 0.9013 sigmau= 0.2643 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.549024, 0.296356\n",
      "first row: -0.092822, -0.092822\n",
      "second row: -1.862391, -1.862391\n",
      "last row: -1.424966, -1.424966\n",
      "no test observations\n",
      "tau: 0.181790\n",
      "nu: 3.000000\n",
      "lambda: 0.082390\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.933191 ... 2.859556\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.549024, 0.296356\n",
      "first row: -0.092822, -0.092822\n",
      "second row: -1.862391, -1.862391\n",
      "last row: -1.424966, -1.424966\n",
      "no test observations\n",
      "tau: 0.181790\n",
      "nu: 3.000000\n",
      "lambda: 0.082390\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.933191 ... 2.859556\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  30 \n",
      "Cumulative average: iter= 1000 beta0= 0.8002 beta= 0.2653 sigmav= 0.8976 sigmau= 0.2452 \n",
      "Cumulative average: iter= 2000 beta0= 0.7981 beta= 0.2648 sigmav= 0.8955 sigmau= 0.2426 \n",
      "Cumulative average: iter= 3000 beta0= 0.823 beta= 0.2637 sigmav= 0.8907 sigmau= 0.2722 \n",
      "Cumulative average: iter= 4000 beta0= 0.8402 beta= 0.2641 sigmav= 0.8875 sigmau= 0.2926 \n",
      "Cumulative average: iter= 5000 beta0= 0.8437 beta= 0.2636 sigmav= 0.8873 sigmau= 0.2973 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.757686, -0.499200\n",
      "first row: 0.897526, 0.897526\n",
      "second row: -0.065580, -0.065580\n",
      "last row: 0.460948, 0.460948\n",
      "no test observations\n",
      "tau: 0.179940\n",
      "nu: 3.000000\n",
      "lambda: 0.061649\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.924816 ... 2.902740\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.757686, -0.499200\n",
      "first row: 0.897526, 0.897526\n",
      "second row: -0.065580, -0.065580\n",
      "last row: 0.460948, 0.460948\n",
      "no test observations\n",
      "tau: 0.179940\n",
      "nu: 3.000000\n",
      "lambda: 0.061649\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.924816 ... 2.902740\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n"
     ]
    }
   ],
   "source": [
    "#set cores for parallel computing\n",
    "RNGkind(\"L'Ecuyer-CMRG\")\n",
    "cores<-strtoi(Sys.getenv('SLURM_CPUS_PER_TASK', unset=1))\n",
    "registerDoMC(cores)\n",
    "\n",
    "part=3\n",
    "\n",
    "res<-foreach(i=21:30) %dopar% {\n",
    "  cat(\"i= \",i,'\\n')\n",
    "\n",
    "finished <- FALSE\n",
    "while(!finished) {\n",
    "    tryCatch({\n",
    "\n",
    "  ##########################################\n",
    "  #    simulate data for linear case       #\n",
    "  ##########################################\n",
    "  ## simulate simple data with one x\n",
    "  beta0=log(2)\n",
    "  beta1=0.2\n",
    "  sigmav=0.9\n",
    "  sigmau=0.2\n",
    "  nsamp=200\n",
    "\n",
    "  x_org=simulated_datasets_R[[i]]$log_X\n",
    "  y_org=simulated_datasets_R[[i]]$log_y\n",
    "\n",
    "\n",
    "  ########################################\n",
    "  # Model 1 fit the Bayes Linear Model\n",
    "  ########################################\n",
    "\n",
    "  simdt=data.frame(y1=y_org,lnx1=x_org)\n",
    "\n",
    "  B_burnin=1000\n",
    "  B_afterburnin=4000\n",
    "\n",
    "  # B_burnin=2\n",
    "  # B_afterburnin=20\n",
    "\n",
    "  res_Bayelin<-Bayeslinear_NHN_fit(B_burnin,\n",
    "                                   B_afterburnin,\n",
    "                                   simdt,\n",
    "                                   beta0_init = 0,\n",
    "                                   beta_init=beta0,\n",
    "                                   sigu_init=sigmau,\n",
    "                                   sigv_init=sigmav,\n",
    "                                   df_v = 5,\n",
    "                                   S_v =(5+2)*sigmav^2,\n",
    "                                   df_u =5,\n",
    "                                   S_u = (5+2)*sigmau^2)\n",
    "\n",
    "\n",
    "  B=B_burnin+B_afterburnin\n",
    "  res_bayes_lin<-na.omit(res_Bayelin$res[B_burnin+1:B,])\n",
    "\n",
    "  ##############################################\n",
    "  # Model 2\n",
    "  # fit SEM-SFM\n",
    "  # imposing monotonicity restrictions on inputs\n",
    "  ##############################################\n",
    "  #first-step: monotone gam, second-step: fan\n",
    "  dati=data.frame(y=y_org,x=x_org)\n",
    "  semfit<-semsfa(y~pbm(x,mono=\"up\"),sem.method = \"gam.mono\",dati)\n",
    "  sigma_v_semfit=sqrt(semfit$sigma^2/(1+semfit$lambda^2))\n",
    "  sigma_u_semfit=semfit$lambda*sigma_v_semfit\n",
    "\n",
    "  ##############################################\n",
    "  # Model 3\n",
    "  # fit Mon-BART-SFM\n",
    "  # imposing monotonicity restrictions on inputs\n",
    "  ##############################################\n",
    "  #find initial value for sigma_v and sigma_u\n",
    "\n",
    "  fit_sfa <-sfa( y1 ~ lnx1,data = simdt)\n",
    "  gamma <- unname( coef(fit_sfa)[\"gamma\"] )\n",
    "  sigmaSq <- unname( coef(fit_sfa)[\"sigmaSq\"] )\n",
    "  sigmaSqU <- gamma * sigmaSq\n",
    "  sigmaSqV <- ( 1 - gamma ) * sigmaSq\n",
    "  betavec<-coef(fit_sfa)[1:3]\n",
    "  sigma_u<-sqrt(sigmaSqU)\n",
    "  sigma_v<-sqrt(sigmaSqV)\n",
    "\n",
    "\n",
    "\n",
    "  ysnfit<-selm(y_org ~ 1, family=\"SN\")\n",
    "  center_Y <- ysnfit@param$dp[1]\n",
    "\n",
    "  nskip=B_burnin\n",
    "  ndpost=B_afterburnin\n",
    "\n",
    "\n",
    "  fitbartsfm<-monbartsfm(\n",
    "    x.train=as.matrix(x_org),y.train=y_org, x.test=matrix(0.0,0,0),\n",
    "    sigest=sigma_v,\n",
    "    sigdf=3,\n",
    "    sigquant=.95,\n",
    "    sigu_pre_est=sigma_u,\n",
    "    sigquant_u=.95,\n",
    "    k=2.0,\n",
    "    power=.8, base=.25, #regular bart is 2,.95\n",
    "    sigmaf=NA,\n",
    "    lambda=NA,\n",
    "    fmean = center_Y,\n",
    "    #fscale=scale_Y,\n",
    "    ntree=100,\n",
    "    ndpost, nskip,\n",
    "    mgsize=50,\n",
    "    nkeeptrain=ndpost,nkeeptest=ndpost,\n",
    "    nkeeptestmean=ndpost,\n",
    "    nkeeptreedraws=ndpost,\n",
    "    printevery=100\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  fitbartsfm_beta0<-monbartsfm_beta0(\n",
    "    x.train=as.matrix(x_org),y.train=y_org, x.test=matrix(0.0,0,0),\n",
    "    sigest=sigma_v,\n",
    "    sigdf=3,\n",
    "    sigquant=.95,\n",
    "    sigu_pre_est=sigma_u,\n",
    "    sigquant_u=.95,\n",
    "    k=2.0,\n",
    "    power=.8, base=.25, #regular bart is 2,.95\n",
    "    sigmaf=NA,\n",
    "    lambda=NA,\n",
    "    fmean = center_Y,\n",
    "    #fscale=scale_Y,\n",
    "    ntree=100,\n",
    "    ndpost, nskip,\n",
    "    mgsize=50,\n",
    "    nkeeptrain=ndpost,nkeeptest=ndpost,\n",
    "    nkeeptestmean=ndpost,\n",
    "    nkeeptreedraws=ndpost,\n",
    "    printevery=100\n",
    "  )\n",
    "\n",
    "  gtest<-geweke.diag(fitbartsfm$sigma_u)\n",
    "  pval_BART<-1-pnorm(gtest$z)\n",
    "  # pval_BART=0.5\n",
    "  gtest_b0<-geweke.diag(fitbartsfm_beta0$sigma_u)\n",
    "  pval_BART_b0<-1-pnorm(gtest_b0$z)\n",
    "  # pval_BART_b0=0.5\n",
    "  finished <- TRUE #if convergence test is passed, then next iteration\n",
    "\n",
    "  if(pval_BART>0.1&pval_BART_b0>0.1){\n",
    "    finished <- TRUE #if convergence test is passed, then next iteration\n",
    "  }\n",
    "\n",
    "  #######################################\n",
    "  # 1. Compare RMSE and BIAS            #\n",
    "  #######################################\n",
    "\n",
    "  y_tf = exp(beta0)*exp(x_org)^beta1 #((X**w_true)*b_true).numpy() \n",
    "  #############################################################################\n",
    "  #formulas are from Eq. 10 and 11 from                                       #\n",
    "  #Ferrara and Vidoli 2017 Semiparametric Stochastic frontier models          #\n",
    "  #############################################################################\n",
    "    \n",
    "  RMSE_bayeslin           = 0 #mean(((mean(res_Bayelin$res$beta0_post)+mean(res_Bayelin$res$beta_current)*x_org-y_org)/y_org)^2) # I did not calculate the Bayes lin\n",
    "  # e_sem = y_org - (semfit$fitted)\n",
    "  # E_sem_correction = mean(exp(e_sem))\n",
    "\n",
    "  E_sem_correction = exp((sigma_v_semfit**2+sigma_u_semfit**2)/2)    \n",
    "  RMSE_sem         = mean(((exp(semfit$fitted)*E_sem_correction-y_tf)/y_tf)^2)\n",
    "  # e_bartsfm = y_org - (fitbartsfm$yhat.train.mean)\n",
    "  # E_bartsfm_correction = mean(exp(e_bartsfm))\n",
    "  sigv_map = median(fitbartsfm$sigma[(nskip+1):(nskip+ndpost)])\n",
    "  sigu_map = median(fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)])\n",
    "  \n",
    "  E_bartsfm_correction =  exp((sigv_map**2+sigv_map**2)/2)    \n",
    "  RMSE_bartsfm            =mean(((exp(fitbartsfm$yhat.train.mean)*E_bartsfm_correction-y_tf)/y_tf)^2)\n",
    "        \n",
    "  # RMSE_bartsfm_uadj       =mean(((fitbartsfm_uadj$yhat.train.mean-y_org)/y_org)^2)\n",
    "  # e_bartsfm_beta0 = y_org - (fitbartsfm_beta0$yhat.train.mean)\n",
    "  # E_bartsfm_beta0_correction = mean(exp(e_bartsfm_beta0))\n",
    "  sigv_beta0_map = median(fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)])\n",
    "  sigu_beta0_map = median(fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)])\n",
    "\n",
    "  E_bartsfm_beta0_correction = exp((sigv_beta0_map**2+sigu_beta0_map**2)/2)   \n",
    "  RMSE_bartsfm_beta0      =mean(((exp(fitbartsfm_beta0$yhat.train.mean)*E_bartsfm_beta0_correction-y_tf)/y_tf)^2)\n",
    "  # RMSE_bartsfm_beta0_uadj =mean(((fitbartsfm_beta0_uadj$yhat.train.mean-y_org)/y_org)^2)\n",
    "\n",
    "  BIAS_bayeslin           =mean(abs((mean(res_Bayelin$res$beta0_post)+mean(res_Bayelin$res$beta_current)*x_org-y_org)/y_org))\n",
    "  BIAS_sem                =mean(abs((exp(semfit$fitted)*E_sem_correction-y_tf)/y_tf))\n",
    "  BIAS_bartsfm            =mean(abs((exp(fitbartsfm$yhat.train.mean)*E_bartsfm_correction-y_tf)/y_tf))\n",
    "  # BIAS_bartsfm_uadj       =median(((fitbartsfm_uadj$yhat.train.mean-y_org)/y_org))\n",
    "  BIAS_bartsfm_beta0      =median(abs((exp(fitbartsfm_beta0$yhat.train.mean)*E_bartsfm_beta0_correction-y_tf)/y_tf))\n",
    "  # BIAS_bartsfm_beta0_uadj =median(((fitbartsfm_beta0_uadj$yhat.train.mean-y_org)/y_org))\n",
    "\n",
    "  RMSE_res<-c(RMSE_bayeslin,\n",
    "              RMSE_sem,\n",
    "              RMSE_bartsfm,\n",
    "            # RMSE_bartsfm_uadj,\n",
    "              RMSE_bartsfm_beta0\n",
    "  )\n",
    "\n",
    "  BIAS_res <- c(BIAS_bayeslin,\n",
    "                BIAS_sem,\n",
    "                BIAS_bartsfm,\n",
    "                # BIAS_bartsfm_uadj,\n",
    "                BIAS_bartsfm_beta0\n",
    "                # BIAS_bartsfm_beta0_uadj\n",
    "                )\n",
    "\n",
    "  ##############################################################################\n",
    "  # 2. Compare mean bias estimates of sigma_u and sigma_v                           #\n",
    "  ##############################################################################\n",
    "  Bias_sig_v_bayeslin           = abs(median(res_bayes_lin$sigv_post)-sigmav)\n",
    "  Bias_sig_v_sem                = abs(sigma_v_semfit-sigmav)\n",
    "  Bias_sig_v_bartsfm            = abs(median(fitbartsfm$sigma[(nskip+1):(nskip+ndpost)])      -sigmav)\n",
    "  # Bias_sig_v_bartsfm_uadj       = abs(median(fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)]) -sigmav)\n",
    "  Bias_sig_v_bartsfm_beta0      = abs(median(fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)])-sigmav)\n",
    "  # Bias_sig_v_bartsfm_beta0_uadj = abs(median(fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)]) -sigmav)\n",
    "\n",
    "  Bias_sig_u_bayeslin           = abs(median(res_bayes_lin$sigu_post)-sigmau)\n",
    "  Bias_sig_u_sem                = abs(sigma_u_semfit-sigmau)\n",
    "  Bias_sig_u_bartsfm            = abs(median(fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)])     -sigmau)\n",
    "  # Bias_sig_u_bartsfm_uadj       = abs(median(fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)])  -sigmau)\n",
    "  Bias_sig_u_bartsfm_beta0      = abs(median(fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)])  -sigmau)\n",
    "  # Bias_sig_u_bartsfm_beta0_uadj = abs(median(fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)])   -sigmau)\n",
    "\n",
    "  Bias_sig_v_res <- c(\n",
    "      Bias_sig_v_bayeslin      ,\n",
    "      Bias_sig_v_sem           ,\n",
    "      Bias_sig_v_bartsfm       ,\n",
    "      # Bias_sig_v_bartsfm_uadj  ,\n",
    "      Bias_sig_v_bartsfm_beta0\n",
    "      # Bias_sig_v_bartsfm_beta0_uadj\n",
    "    )\n",
    "\n",
    "  Bias_sig_u_res <-\n",
    "    c(Bias_sig_u_bayeslin      ,\n",
    "      Bias_sig_u_sem           ,\n",
    "      Bias_sig_u_bartsfm       ,\n",
    "      # Bias_sig_u_bartsfm_uadj  ,\n",
    "      Bias_sig_u_bartsfm_beta0\n",
    "      # Bias_sig_u_bartsfm_beta0_uadj\n",
    "    )\n",
    "\n",
    "\n",
    "  ##############################################################################\n",
    "  # 3. Compare mean inefficiency scores                                        #\n",
    "  ##############################################################################\n",
    "  #True TEs\n",
    "  res_true<-simdt$y1-(beta0+beta1*simdt$lnx1)\n",
    "  TEvec_true<-sapply(res_true,TE_fun,sigv=sigmav,sigu=sigmau)\n",
    "  mean(TEvec_true)\n",
    "\n",
    "  #Bayes regression TEs\n",
    "  TEvec_bayeslin<-apply(res_bayes_lin,1,function(x){ return(TE_bayes_fun(bayelinres = x,y = simdt$y1,x=simdt$lnx1))})\n",
    "  mean(TEvec_bayeslin)\n",
    "\n",
    "  #TE for sem\n",
    "  res_sem<-simdt$y1-semfit$fitted\n",
    "  TEvec_sem<-sapply(res_sem,TE_fun,sigv=sigma_v_semfit,sigu=sigma_u_semfit)\n",
    "  mean(TEvec_sem)\n",
    "\n",
    "  #TE for bart-sfm\n",
    "  TEvec_bartsfm<-apply(cbind(fitbartsfm$yhat.train,\n",
    "                             fitbartsfm$sigma[(nskip+1):(nskip+ndpost)],\n",
    "                             fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "                       function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "                                                      sigv_post = y[nsamp+1],\n",
    "                                                      sigu_post = y[nsamp+2],\n",
    "                                                      y_bart = simdt$y1\n",
    "                       ))})\n",
    "\n",
    "  #TE for bart-sfm-uadj\n",
    "  # TEvec_bartsfm_uadj<-apply(cbind(fitbartsfm_uadj$yhat.train,\n",
    "  #                                 fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)],\n",
    "  #                                 fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "  #                           function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "  #                                                          sigv_post = y[nsamp+1],\n",
    "  #                                                          sigu_post = y[nsamp+2],\n",
    "  #                                                          y_bart = simdt$y1\n",
    "  #                           ))})\n",
    "\n",
    "  #TE for bart-sfm-beta0\n",
    "  TEvec_bartsfm_beta0<-apply(cbind(fitbartsfm_beta0$yhat.train,\n",
    "                                   fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)],\n",
    "                                   fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "                             function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "                                                            sigv_post = y[nsamp+1],\n",
    "                                                            sigu_post = y[nsamp+2],\n",
    "                                                            y_bart = simdt$y1\n",
    "                             ))})\n",
    "\n",
    "\n",
    "  #TE for bart-sfm-beta0-uadj\n",
    "  # TEvec_bartsfm_beta0_uadj<-apply(cbind(fitbartsfm_beta0_uadj$yhat.train,\n",
    "  #                                       fitbartsfm_beta0_uadj$sigma[(nskip+1):(nskip+ndpost)],\n",
    "  #                                       fitbartsfm_beta0_uadj$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "  #                                 function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "  #                                                                sigv_post = y[nsamp+1],\n",
    "  #                                                                sigu_post = y[nsamp+2],\n",
    "  #                                                                y_bart = simdt$y1\n",
    "  #                                 ))})\n",
    "\n",
    "  TE_bias<-abs(c(\n",
    "    mean(TEvec_bayeslin),\n",
    "    mean(TEvec_sem),\n",
    "    mean(TEvec_bartsfm),\n",
    "    # mean(TEvec_bartsfm_uadj),\n",
    "    mean(TEvec_bartsfm_beta0)\n",
    "    # mean(TEvec_bartsfm_beta0_uadj)\n",
    "  )-mean(TEvec_true))\n",
    "\n",
    "    },\n",
    "  error = function(e) {})\n",
    "}\n",
    "\n",
    "  # TE_bias<-rbind(TE_bias,TE_bias_one)\n",
    "\n",
    "  return(list(RMSE=RMSE_res,\n",
    "              BIAS=BIAS_res,\n",
    "              Bias_sig_v=Bias_sig_v_res,\n",
    "              Bias_sig_u=Bias_sig_u_res,\n",
    "              TE_bias=TE_bias,\n",
    "              simdata=simdt,\n",
    "              sig_v_bart_post=fitbartsfm$sigma,\n",
    "              sig_u_bart_post=fitbartsfm$sigma_u,\n",
    "              sig_v_bart_b0_post=fitbartsfm_beta0$sigma,\n",
    "              sig_u_bart_b0_post=fitbartsfm_beta0$sigma_u\n",
    "              ))\n",
    "\n",
    "}\n",
    "\n",
    "RMSE_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[1]]})))\n",
    "colnames(RMSE_res)<-c(\"RMSE_BayesLin\",\"RMSE_Sem\",\n",
    "                      \"RMSE_Bart\",\n",
    "                      # \"RMSE_Bart_uadj\",\n",
    "                      \"RMSE_Bart_b0\"\n",
    "                      # \"RMSE_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "BIAS_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[2]]})))\n",
    "colnames(BIAS_res)<-c(\"BIAS_BayesLin\",\"BIAS_Sem\",\n",
    "                      \"BIAS_Bart\",\n",
    "                      # \"BIAS_Bart_uadj\",\n",
    "                      \"BIAS_Bart_b0\"\n",
    "                      # \"BIAS_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "Bias_sig_v_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[3]]})))\n",
    "colnames(Bias_sig_v_res)<-c(\"Sigvb_BayesLin\",\"Sigvb_Sem\",\n",
    "                            \"Sigvb_Bart\",\n",
    "                            # \"Sigvb_Bart_uadj\",\n",
    "                            \"Sigvb_Bart_b0\"\n",
    "                            # \"Sigvb_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "Bias_sig_u_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[4]]})))\n",
    "colnames(Bias_sig_u_res)<-c(\"Sigub_BayesLin\",\n",
    "                            \"Sigub_Sem\",\n",
    "                            \"Sigub_Bart\",\n",
    "                            # \"Sigub_Bart_uadj\",\n",
    "                            \"Sigub_Bart_b0\"\n",
    "                            # \"Sigub_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "TE_bias<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[5]]})))\n",
    "colnames(TE_bias)<-c(\"TEb_BayesLin\",\"TEb_Sem\",\n",
    "                     \"TEb_Bart\",\n",
    "                     # \"TEb_Bart_uadj\",\n",
    "                     \"TEb_Bart_b0\"\n",
    "                     # \"TEb_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "resfin<-list(RMSE=RMSE_res,\n",
    "             BIAS=BIAS_res,\n",
    "             Bias_sigv=Bias_sig_v_res,\n",
    "             Bias_sigu=Bias_sig_u_res,\n",
    "             TE_bias=TE_bias,\n",
    "             res=res)\n",
    "saveRDS(resfin, paste(\"res/linear_case_part\",part,\".rds\",sep = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e602a7-73c7-43ea-81ed-de4ea77b91ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R_monbart",
   "language": "R",
   "name": "r4.1.2_monbart"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
