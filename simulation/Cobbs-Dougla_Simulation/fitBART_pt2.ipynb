{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3dc942-cad4-49a5-abfb-8c2cf4cc8fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘foreach’ was built under R version 4.2.3”\n",
      "Loading required package: iterators\n",
      "\n",
      "Warning message:\n",
      "“package ‘iterators’ was built under R version 4.2.3”\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: micEcon\n",
      "\n",
      "\n",
      "If you have questions, suggestions, or comments regarding one of the 'micEcon' packages, please use a forum or 'tracker' at micEcon's R-Forge site:\n",
      "https://r-forge.r-project.org/projects/micecon/\n",
      "\n",
      "Loading required package: lmtest\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "\n",
      "Please cite the 'frontier' package as:\n",
      "Tim Coelli and Arne Henningsen (2013). frontier: Stochastic Frontier Analysis. R package version 1.1. http://CRAN.R-Project.org/package=frontier.\n",
      "\n",
      "If you have questions, suggestions, or comments regarding the 'frontier' package, please use a forum or 'tracker' at frontier's R-Forge site:\n",
      "https://r-forge.r-project.org/projects/frontier/\n",
      "\n",
      "Loading required package: stats4\n",
      "\n",
      "\n",
      "Attaching package: ‘sn’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    sd\n",
      "\n",
      "\n",
      "Loading required package: mgcv\n",
      "\n",
      "Loading required package: nlme\n",
      "\n",
      "This is mgcv 1.8-41. For overview type 'help(\"mgcv-package\")'.\n",
      "\n",
      "Loading required package: np\n",
      "\n",
      "Warning message:\n",
      "“package ‘np’ was built under R version 4.2.3”\n",
      "Nonparametric Kernel Methods for Mixed Datatypes (version 0.60-17)\n",
      "[vignette(\"np_faq\",package=\"np\") provides answers to frequently asked questions]\n",
      "[vignette(\"np\",package=\"np\") an overview]\n",
      "[vignette(\"entropy_np\",package=\"np\") an overview of entropy-based methods]\n",
      "\n",
      "Loading required package: gamlss\n",
      "\n",
      "Loading required package: splines\n",
      "\n",
      "Loading required package: gamlss.data\n",
      "\n",
      "\n",
      "Attaching package: ‘gamlss.data’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:datasets’:\n",
      "\n",
      "    sleep\n",
      "\n",
      "\n",
      "Loading required package: gamlss.dist\n",
      "\n",
      " **********   GAMLSS Version 5.4-3  ********** \n",
      "\n",
      "For more on GAMLSS look at https://www.gamlss.com/\n",
      "\n",
      "Type gamlssNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rm(list = ls())\n",
    "#setwd('/Users/zhengwei/Desktop/OneDrive - Texas A&M University-Corpus Christi/Research/Huiyan_Sang/DecisionTree/MyPackage/sim1_lin')\n",
    "#setwd(\"/Users/zhengwei/OneDrive - Texas A&M University-Corpus Christi/Research/Huiyan_Sang/DecisionTree/MyPackage/sim1_lin\")\n",
    "\n",
    "library(foreach)\n",
    "library(doMC)\n",
    "library(coda)\n",
    "library(MonBartSFM)\n",
    "library(frontier)\n",
    "library(truncnorm)\n",
    "library(sn)\n",
    "library(MASS)\n",
    "library(semsfa)\n",
    "source(\"otherfuns.R\")\n",
    "source(\"Bayes_SFM_NHN_Gibbs.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfa84ef-70e6-43a7-9dc4-a041485f99a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>log_X</th><th scope=col>log_y</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 2.768552</td><td> 0.2527462</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>-2.856968</td><td>-0.6890037</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>-1.137870</td><td> 0.5694323</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 2.452089</td><td> 2.5354790</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>-1.278954</td><td> 1.4797850</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-1.649340</td><td> 0.2519563</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & log\\_X & log\\_y\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 &  2.768552 &  0.2527462\\\\\n",
       "\t2 & -2.856968 & -0.6890037\\\\\n",
       "\t3 & -1.137870 &  0.5694323\\\\\n",
       "\t4 &  2.452089 &  2.5354790\\\\\n",
       "\t5 & -1.278954 &  1.4797850\\\\\n",
       "\t6 & -1.649340 &  0.2519563\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | log_X &lt;dbl&gt; | log_y &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 |  2.768552 |  0.2527462 |\n",
       "| 2 | -2.856968 | -0.6890037 |\n",
       "| 3 | -1.137870 |  0.5694323 |\n",
       "| 4 |  2.452089 |  2.5354790 |\n",
       "| 5 | -1.278954 |  1.4797850 |\n",
       "| 6 | -1.649340 |  0.2519563 |\n",
       "\n"
      ],
      "text/plain": [
       "  log_X     log_y     \n",
       "1  2.768552  0.2527462\n",
       "2 -2.856968 -0.6890037\n",
       "3 -1.137870  0.5694323\n",
       "4  2.452089  2.5354790\n",
       "5 -1.278954  1.4797850\n",
       "6 -1.649340  0.2519563"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set path to your folder\n",
    "path <- \"simulated_data\"\n",
    "\n",
    "# List all CSV files in that folder\n",
    "files <- list.files(path, pattern = \"\\\\.csv$\", full.names = TRUE)\n",
    "\n",
    "# Read each CSV into a list of data.frames\n",
    "simulated_datasets_R <- lapply(files, read.csv)\n",
    "\n",
    "# Access the first dataset\n",
    "head(simulated_datasets_R[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6104df-bd6e-4587-9a42-6a1902d2d3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  11 \n",
      "Cumulative average: iter= 1000 beta0= 0.8041 beta= 0.2326 sigmav= 0.9388 sigmau= 0.2954 \n",
      "Cumulative average: iter= 2000 beta0= 0.8084 beta= 0.2326 sigmav= 0.9357 sigmau= 0.2991 \n",
      "Cumulative average: iter= 3000 beta0= 0.8123 beta= 0.2333 sigmav= 0.9346 sigmau= 0.3034 \n",
      "Cumulative average: iter= 4000 beta0= 0.8144 beta= 0.2331 sigmav= 0.9345 sigmau= 0.3071 \n",
      "Cumulative average: iter= 5000 beta0= 0.8115 beta= 0.2331 sigmav= 0.9344 sigmau= 0.3044 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.505086, 0.303727\n",
      "first row: 1.758623, 1.758623\n",
      "second row: -0.482557, -0.482557\n",
      "last row: -1.667174, -1.667174\n",
      "no test observations\n",
      "tau: 0.166920\n",
      "nu: 3.000000\n",
      "lambda: 0.080404\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.887513 ... 2.935130\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.505086, 0.303727\n",
      "first row: 1.758623, 1.758623\n",
      "second row: -0.482557, -0.482557\n",
      "last row: -1.667174, -1.667174\n",
      "no test observations\n",
      "tau: 0.166920\n",
      "nu: 3.000000\n",
      "lambda: 0.080404\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.887513 ... 2.935130\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  12 \n",
      "Cumulative average: iter= 1000 beta0= 0.8091 beta= 0.2086 sigmav= 0.9425 sigmau= 0.2851 \n",
      "Cumulative average: iter= 2000 beta0= 0.8126 beta= 0.2077 sigmav= 0.9426 sigmau= 0.2864 \n",
      "Cumulative average: iter= 3000 beta0= 0.802 beta= 0.2073 sigmav= 0.9437 sigmau= 0.2747 \n",
      "Cumulative average: iter= 4000 beta0= 0.7948 beta= 0.2073 sigmav= 0.9443 sigmau= 0.2648 \n",
      "Cumulative average: iter= 5000 beta0= 0.8059 beta= 0.2075 sigmav= 0.9415 sigmau= 0.2792 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -2.280802, -0.571805\n",
      "first row: -1.837907, -1.837907\n",
      "second row: -0.483917, -0.483917\n",
      "last row: 2.936803, 2.936803\n",
      "no test observations\n",
      "tau: 0.178864\n",
      "nu: 3.000000\n",
      "lambda: 0.058039\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.922214 ... 2.926797\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -2.280802, -0.571805\n",
      "first row: -1.837907, -1.837907\n",
      "second row: -0.483917, -0.483917\n",
      "last row: 2.936803, 2.936803\n",
      "no test observations\n",
      "tau: 0.178864\n",
      "nu: 3.000000\n",
      "lambda: 0.058039\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.922214 ... 2.926797\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  13 \n",
      "Cumulative average: iter= 1000 beta0= 0.7029 beta= 0.214 sigmav= 0.9535 sigmau= 0.2319 \n",
      "Cumulative average: iter= 2000 beta0= 0.7035 beta= 0.2125 sigmav= 0.9539 sigmau= 0.2309 \n",
      "Cumulative average: iter= 3000 beta0= 0.7129 beta= 0.2139 sigmav= 0.9535 sigmau= 0.2435 \n",
      "Cumulative average: iter= 4000 beta0= 0.7267 beta= 0.214 sigmav= 0.952 sigmau= 0.2602 \n",
      "Cumulative average: iter= 5000 beta0= 0.7352 beta= 0.2138 sigmav= 0.951 sigmau= 0.2701 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.183566, 1.066254\n",
      "first row: 0.889249, 0.889249\n",
      "second row: 1.274235, 1.274235\n",
      "last row: -0.388718, -0.388718\n",
      "no test observations\n",
      "tau: 0.174185\n",
      "nu: 3.000000\n",
      "lambda: 0.106650\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.936828 ... 2.917285\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.183566, 1.066254\n",
      "first row: 0.889249, 0.889249\n",
      "second row: 1.274235, 1.274235\n",
      "last row: -0.388718, -0.388718\n",
      "no test observations\n",
      "tau: 0.174185\n",
      "nu: 3.000000\n",
      "lambda: 0.106650\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.936828 ... 2.917285\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  14 \n",
      "Cumulative average: iter= 1000 beta0= 0.683 beta= 0.198 sigmav= 0.8638 sigmau= 0.287 \n",
      "Cumulative average: iter= 2000 beta0= 0.7048 beta= 0.196 sigmav= 0.8579 sigmau= 0.3114 \n",
      "Cumulative average: iter= 3000 beta0= 0.6974 beta= 0.1962 sigmav= 0.8586 sigmau= 0.3002 \n",
      "Cumulative average: iter= 4000 beta0= 0.6918 beta= 0.1966 sigmav= 0.8606 sigmau= 0.2929 \n",
      "Cumulative average: iter= 5000 beta0= 0.6903 beta= 0.1965 sigmav= 0.8611 sigmau= 0.2913 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.985978, 1.283423\n",
      "first row: -0.680526, -0.680526\n",
      "second row: 1.089467, 1.089467\n",
      "last row: 2.121863, 2.121863\n",
      "no test observations\n",
      "tau: 0.157006\n",
      "nu: 3.000000\n",
      "lambda: 0.065259\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.935449 ... 2.926171\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.985978, 1.283423\n",
      "first row: -0.680526, -0.680526\n",
      "second row: 1.089467, 1.089467\n",
      "last row: 2.121863, 2.121863\n",
      "no test observations\n",
      "tau: 0.157006\n",
      "nu: 3.000000\n",
      "lambda: 0.065259\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.935449 ... 2.926171\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  15 \n",
      "Cumulative average: iter= 1000 beta0= 0.6784 beta= 0.2198 sigmav= 0.931 sigmau= 0.3154 \n",
      "Cumulative average: iter= 2000 beta0= 0.6649 beta= 0.2207 sigmav= 0.9348 sigmau= 0.3 \n",
      "Cumulative average: iter= 3000 beta0= 0.6503 beta= 0.2214 sigmav= 0.9365 sigmau= 0.2826 \n",
      "Cumulative average: iter= 4000 beta0= 0.6447 beta= 0.2209 sigmav= 0.9385 sigmau= 0.2754 \n",
      "Cumulative average: iter= 5000 beta0= 0.6412 beta= 0.2207 sigmav= 0.939 sigmau= 0.2705 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.014708, -0.955789\n",
      "first row: -1.417058, -1.417058\n",
      "second row: -2.802220, -2.802220\n",
      "last row: -1.082604, -1.082604\n",
      "no test observations\n",
      "tau: 0.182272\n",
      "nu: 3.000000\n",
      "lambda: 0.104277\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.927617 ... 2.898250\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.014708, -0.955789\n",
      "first row: -1.417058, -1.417058\n",
      "second row: -2.802220, -2.802220\n",
      "last row: -1.082604, -1.082604\n",
      "no test observations\n",
      "tau: 0.182272\n",
      "nu: 3.000000\n",
      "lambda: 0.104277\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.927617 ... 2.898250\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  16 \n",
      "Cumulative average: iter= 1000 beta0= 0.8102 beta= 0.1869 sigmav= 0.9035 sigmau= 0.281 \n",
      "Cumulative average: iter= 2000 beta0= 0.7989 beta= 0.1864 sigmav= 0.9038 sigmau= 0.2629 \n",
      "Cumulative average: iter= 3000 beta0= 0.8001 beta= 0.1866 sigmav= 0.9035 sigmau= 0.2651 \n",
      "Cumulative average: iter= 4000 beta0= 0.8053 beta= 0.1869 sigmav= 0.9026 sigmau= 0.2711 \n",
      "Cumulative average: iter= 5000 beta0= 0.8066 beta= 0.1871 sigmav= 0.903 sigmau= 0.2718 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.339756, -0.161201\n",
      "first row: -0.103543, -0.103543\n",
      "second row: 2.688452, 2.688452\n",
      "last row: 2.503835, 2.503835\n",
      "no test observations\n",
      "tau: 0.160698\n",
      "nu: 3.000000\n",
      "lambda: 0.096497\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.937885 ... 2.885256\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.339756, -0.161201\n",
      "first row: -0.103543, -0.103543\n",
      "second row: 2.688452, 2.688452\n",
      "last row: 2.503835, 2.503835\n",
      "no test observations\n",
      "tau: 0.160698\n",
      "nu: 3.000000\n",
      "lambda: 0.096497\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.937885 ... 2.885256\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  17 \n",
      "Cumulative average: iter= 1000 beta0= 0.6268 beta= 0.1987 sigmav= 0.9976 sigmau= 0.2772 \n",
      "Cumulative average: iter= 2000 beta0= 0.6168 beta= 0.1984 sigmav= 0.9979 sigmau= 0.2666 \n",
      "Cumulative average: iter= 3000 beta0= 0.6154 beta= 0.1985 sigmav= 0.9969 sigmau= 0.2643 \n",
      "Cumulative average: iter= 4000 beta0= 0.6101 beta= 0.1981 sigmav= 0.9971 sigmau= 0.2591 \n",
      "Cumulative average: iter= 5000 beta0= 0.6099 beta= 0.1979 sigmav= 0.9965 sigmau= 0.2595 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.522073, -0.830659\n",
      "first row: -2.534471, -2.534471\n",
      "second row: 0.852036, 0.852036\n",
      "last row: 1.038083, 1.038083\n",
      "no test observations\n",
      "tau: 0.176366\n",
      "nu: 3.000000\n",
      "lambda: 0.086827\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.939431 ... 2.916532\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.522073, -0.830659\n",
      "first row: -2.534471, -2.534471\n",
      "second row: 0.852036, 0.852036\n",
      "last row: 1.038083, 1.038083\n",
      "no test observations\n",
      "tau: 0.176366\n",
      "nu: 3.000000\n",
      "lambda: 0.086827\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.939431 ... 2.916532\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  18 \n",
      "Cumulative average: iter= 1000 beta0= 0.6452 beta= 0.1534 sigmav= 0.969 sigmau= 0.2538 \n",
      "Cumulative average: iter= 2000 beta0= 0.656 beta= 0.1528 sigmav= 0.9671 sigmau= 0.2666 \n",
      "Cumulative average: iter= 3000 beta0= 0.67 beta= 0.152 sigmav= 0.9651 sigmau= 0.283 \n",
      "Cumulative average: iter= 4000 beta0= 0.6709 beta= 0.1522 sigmav= 0.9654 sigmau= 0.2851 \n",
      "Cumulative average: iter= 5000 beta0= 0.6688 beta= 0.1519 sigmav= 0.9656 sigmau= 0.2817 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.126231, -1.013464\n",
      "first row: -2.524313, -2.524313\n",
      "second row: -2.965139, -2.965139\n",
      "last row: 1.461883, 1.461883\n",
      "no test observations\n",
      "tau: 0.162698\n",
      "nu: 3.000000\n",
      "lambda: 0.085888\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.915449 ... 2.899749\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.126231, -1.013464\n",
      "first row: -2.524313, -2.524313\n",
      "second row: -2.965139, -2.965139\n",
      "last row: 1.461883, 1.461883\n",
      "no test observations\n",
      "tau: 0.162698\n",
      "nu: 3.000000\n",
      "lambda: 0.085888\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.915449 ... 2.899749\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  19 \n",
      "Cumulative average: iter= 1000 beta0= 0.7328 beta= 0.1547 sigmav= 0.9323 sigmau= 0.2663 \n",
      "Cumulative average: iter= 2000 beta0= 0.753 beta= 0.1551 sigmav= 0.9262 sigmau= 0.2944 \n",
      "Cumulative average: iter= 3000 beta0= 0.7367 beta= 0.1549 sigmav= 0.9305 sigmau= 0.2737 \n",
      "Cumulative average: iter= 4000 beta0= 0.7382 beta= 0.1547 sigmav= 0.9295 sigmau= 0.2762 \n",
      "Cumulative average: iter= 5000 beta0= 0.7395 beta= 0.1546 sigmav= 0.9288 sigmau= 0.2779 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.015885, -1.196151\n",
      "first row: -0.385466, -0.385466\n",
      "second row: 1.853865, 1.853865\n",
      "last row: 2.321208, 2.321208\n",
      "no test observations\n",
      "tau: 0.199215\n",
      "nu: 3.000000\n",
      "lambda: 0.070415\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.902471 ... 2.929490\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.015885, -1.196151\n",
      "first row: -0.385466, -0.385466\n",
      "second row: 1.853865, 1.853865\n",
      "last row: 2.321208, 2.321208\n",
      "no test observations\n",
      "tau: 0.199215\n",
      "nu: 3.000000\n",
      "lambda: 0.070415\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.902471 ... 2.929490\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  20 \n",
      "Cumulative average: iter= 1000 beta0= 0.7568 beta= 0.1687 sigmav= 0.8959 sigmau= 0.2313 \n",
      "Cumulative average: iter= 2000 beta0= 0.7694 beta= 0.1687 sigmav= 0.8915 sigmau= 0.2457 \n",
      "Cumulative average: iter= 3000 beta0= 0.7748 beta= 0.169 sigmav= 0.89 sigmau= 0.2531 \n",
      "Cumulative average: iter= 4000 beta0= 0.7761 beta= 0.1692 sigmav= 0.8904 sigmau= 0.2544 \n",
      "Cumulative average: iter= 5000 beta0= 0.7928 beta= 0.1691 sigmav= 0.8878 sigmau= 0.2744 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.332031, -0.345569\n",
      "first row: -0.403711, -0.403711\n",
      "second row: -0.248450, -0.248450\n",
      "last row: 2.832672, 2.832672\n",
      "no test observations\n",
      "tau: 0.152331\n",
      "nu: 3.000000\n",
      "lambda: 0.093339\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.913147 ... 2.929169\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.332031, -0.345569\n",
      "first row: -0.403711, -0.403711\n",
      "second row: -0.248450, -0.248450\n",
      "last row: 2.832672, 2.832672\n",
      "no test observations\n",
      "tau: 0.152331\n",
      "nu: 3.000000\n",
      "lambda: 0.093339\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.913147 ... 2.929169\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n"
     ]
    }
   ],
   "source": [
    "#set cores for parallel computing\n",
    "RNGkind(\"L'Ecuyer-CMRG\")\n",
    "cores<-strtoi(Sys.getenv('SLURM_CPUS_PER_TASK', unset=1))\n",
    "registerDoMC(cores)\n",
    "\n",
    "part=2\n",
    "\n",
    "res<-foreach(i=11:20) %dopar% {\n",
    "  cat(\"i= \",i,'\\n')\n",
    "\n",
    "finished <- FALSE\n",
    "while(!finished) {\n",
    "    tryCatch({\n",
    "\n",
    "  ##########################################\n",
    "  #    simulate data for linear case       #\n",
    "  ##########################################\n",
    "  ## simulate simple data with one x\n",
    "  beta0=log(2)\n",
    "  beta1=0.2\n",
    "  sigmav=0.9\n",
    "  sigmau=0.2\n",
    "  nsamp=200\n",
    "\n",
    "  x_org=simulated_datasets_R[[i]]$log_X\n",
    "  y_org=simulated_datasets_R[[i]]$log_y\n",
    "\n",
    "\n",
    "  ########################################\n",
    "  # Model 1 fit the Bayes Linear Model\n",
    "  ########################################\n",
    "\n",
    "  simdt=data.frame(y1=y_org,lnx1=x_org)\n",
    "\n",
    "  B_burnin=1000\n",
    "  B_afterburnin=4000\n",
    "\n",
    "  # B_burnin=2\n",
    "  # B_afterburnin=20\n",
    "\n",
    "  res_Bayelin<-Bayeslinear_NHN_fit(B_burnin,\n",
    "                                   B_afterburnin,\n",
    "                                   simdt,\n",
    "                                   beta0_init = 0,\n",
    "                                   beta_init=beta0,\n",
    "                                   sigu_init=sigmau,\n",
    "                                   sigv_init=sigmav,\n",
    "                                   df_v = 5,\n",
    "                                   S_v =(5+2)*sigmav^2,\n",
    "                                   df_u =5,\n",
    "                                   S_u = (5+2)*sigmau^2)\n",
    "\n",
    "\n",
    "  B=B_burnin+B_afterburnin\n",
    "  res_bayes_lin<-na.omit(res_Bayelin$res[B_burnin+1:B,])\n",
    "\n",
    "  ##############################################\n",
    "  # Model 2\n",
    "  # fit SEM-SFM\n",
    "  # imposing monotonicity restrictions on inputs\n",
    "  ##############################################\n",
    "  #first-step: monotone gam, second-step: fan\n",
    "  dati=data.frame(y=y_org,x=x_org)\n",
    "  semfit<-semsfa(y~pbm(x,mono=\"up\"),sem.method = \"gam.mono\",dati)\n",
    "  sigma_v_semfit=sqrt(semfit$sigma^2/(1+semfit$lambda^2))\n",
    "  sigma_u_semfit=semfit$lambda*sigma_v_semfit\n",
    "\n",
    "  ##############################################\n",
    "  # Model 3\n",
    "  # fit Mon-BART-SFM\n",
    "  # imposing monotonicity restrictions on inputs\n",
    "  ##############################################\n",
    "  #find initial value for sigma_v and sigma_u\n",
    "\n",
    "  fit_sfa <-sfa( y1 ~ lnx1,data = simdt)\n",
    "  gamma <- unname( coef(fit_sfa)[\"gamma\"] )\n",
    "  sigmaSq <- unname( coef(fit_sfa)[\"sigmaSq\"] )\n",
    "  sigmaSqU <- gamma * sigmaSq\n",
    "  sigmaSqV <- ( 1 - gamma ) * sigmaSq\n",
    "  betavec<-coef(fit_sfa)[1:3]\n",
    "  sigma_u<-sqrt(sigmaSqU)\n",
    "  sigma_v<-sqrt(sigmaSqV)\n",
    "\n",
    "\n",
    "\n",
    "  ysnfit<-selm(y_org ~ 1, family=\"SN\")\n",
    "  center_Y <- ysnfit@param$dp[1]\n",
    "\n",
    "  nskip=B_burnin\n",
    "  ndpost=B_afterburnin\n",
    "\n",
    "\n",
    "  fitbartsfm<-monbartsfm(\n",
    "    x.train=as.matrix(x_org),y.train=y_org, x.test=matrix(0.0,0,0),\n",
    "    sigest=sigma_v,\n",
    "    sigdf=3,\n",
    "    sigquant=.95,\n",
    "    sigu_pre_est=sigma_u,\n",
    "    sigquant_u=.95,\n",
    "    k=2.0,\n",
    "    power=.8, base=.25, #regular bart is 2,.95\n",
    "    sigmaf=NA,\n",
    "    lambda=NA,\n",
    "    fmean = center_Y,\n",
    "    #fscale=scale_Y,\n",
    "    ntree=100,\n",
    "    ndpost, nskip,\n",
    "    mgsize=50,\n",
    "    nkeeptrain=ndpost,nkeeptest=ndpost,\n",
    "    nkeeptestmean=ndpost,\n",
    "    nkeeptreedraws=ndpost,\n",
    "    printevery=100\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  fitbartsfm_beta0<-monbartsfm_beta0(\n",
    "    x.train=as.matrix(x_org),y.train=y_org, x.test=matrix(0.0,0,0),\n",
    "    sigest=sigma_v,\n",
    "    sigdf=3,\n",
    "    sigquant=.95,\n",
    "    sigu_pre_est=sigma_u,\n",
    "    sigquant_u=.95,\n",
    "    k=2.0,\n",
    "    power=.8, base=.25, #regular bart is 2,.95\n",
    "    sigmaf=NA,\n",
    "    lambda=NA,\n",
    "    fmean = center_Y,\n",
    "    #fscale=scale_Y,\n",
    "    ntree=100,\n",
    "    ndpost, nskip,\n",
    "    mgsize=50,\n",
    "    nkeeptrain=ndpost,nkeeptest=ndpost,\n",
    "    nkeeptestmean=ndpost,\n",
    "    nkeeptreedraws=ndpost,\n",
    "    printevery=100\n",
    "  )\n",
    "\n",
    "  gtest<-geweke.diag(fitbartsfm$sigma_u)\n",
    "  pval_BART<-1-pnorm(gtest$z)\n",
    "  # pval_BART=0.5\n",
    "  gtest_b0<-geweke.diag(fitbartsfm_beta0$sigma_u)\n",
    "  pval_BART_b0<-1-pnorm(gtest_b0$z)\n",
    "  # pval_BART_b0=0.5\n",
    "  finished <- TRUE #if convergence test is passed, then next iteration\n",
    "\n",
    "  if(pval_BART>0.1&pval_BART_b0>0.1){\n",
    "    finished <- TRUE #if convergence test is passed, then next iteration\n",
    "  }\n",
    "\n",
    "  #######################################\n",
    "  # 1. Compare RMSE and BIAS            #\n",
    "  #######################################\n",
    "\n",
    "  y_tf = exp(beta0)*exp(x_org)^beta1 #((X**w_true)*b_true).numpy() \n",
    "  #############################################################################\n",
    "  #formulas are from Eq. 10 and 11 from                                       #\n",
    "  #Ferrara and Vidoli 2017 Semiparametric Stochastic frontier models          #\n",
    "  #############################################################################\n",
    "    \n",
    "  RMSE_bayeslin           = 0 #mean(((mean(res_Bayelin$res$beta0_post)+mean(res_Bayelin$res$beta_current)*x_org-y_org)/y_org)^2) # I did not calculate the Bayes lin\n",
    "  # e_sem = y_org - (semfit$fitted)\n",
    "  # E_sem_correction = mean(exp(e_sem))\n",
    "\n",
    "  E_sem_correction = exp((sigma_v_semfit**2+sigma_u_semfit**2)/2)    \n",
    "  RMSE_sem         = mean(((exp(semfit$fitted)*E_sem_correction-y_tf)/y_tf)^2)\n",
    "  # e_bartsfm = y_org - (fitbartsfm$yhat.train.mean)\n",
    "  # E_bartsfm_correction = mean(exp(e_bartsfm))\n",
    "  sigv_map = median(fitbartsfm$sigma[(nskip+1):(nskip+ndpost)])\n",
    "  sigu_map = median(fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)])\n",
    "  \n",
    "  E_bartsfm_correction =  exp((sigv_map**2+sigv_map**2)/2)    \n",
    "  RMSE_bartsfm            =mean(((exp(fitbartsfm$yhat.train.mean)*E_bartsfm_correction-y_tf)/y_tf)^2)\n",
    "        \n",
    "  # RMSE_bartsfm_uadj       =mean(((fitbartsfm_uadj$yhat.train.mean-y_org)/y_org)^2)\n",
    "  # e_bartsfm_beta0 = y_org - (fitbartsfm_beta0$yhat.train.mean)\n",
    "  # E_bartsfm_beta0_correction = mean(exp(e_bartsfm_beta0))\n",
    "  sigv_beta0_map = median(fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)])\n",
    "  sigu_beta0_map = median(fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)])\n",
    "\n",
    "  E_bartsfm_beta0_correction = exp((sigv_beta0_map**2+sigu_beta0_map**2)/2)   \n",
    "  RMSE_bartsfm_beta0      =mean(((exp(fitbartsfm_beta0$yhat.train.mean)*E_bartsfm_beta0_correction-y_tf)/y_tf)^2)\n",
    "  # RMSE_bartsfm_beta0_uadj =mean(((fitbartsfm_beta0_uadj$yhat.train.mean-y_org)/y_org)^2)\n",
    "\n",
    "  BIAS_bayeslin           =mean(abs((mean(res_Bayelin$res$beta0_post)+mean(res_Bayelin$res$beta_current)*x_org-y_org)/y_org))\n",
    "  BIAS_sem                =mean(abs((exp(semfit$fitted)*E_sem_correction-y_tf)/y_tf))\n",
    "  BIAS_bartsfm            =mean(abs((exp(fitbartsfm$yhat.train.mean)*E_bartsfm_correction-y_tf)/y_tf))\n",
    "  # BIAS_bartsfm_uadj       =median(((fitbartsfm_uadj$yhat.train.mean-y_org)/y_org))\n",
    "  BIAS_bartsfm_beta0      =median(abs((exp(fitbartsfm_beta0$yhat.train.mean)*E_bartsfm_beta0_correction-y_tf)/y_tf))\n",
    "  # BIAS_bartsfm_beta0_uadj =median(((fitbartsfm_beta0_uadj$yhat.train.mean-y_org)/y_org))\n",
    "\n",
    "  RMSE_res<-c(RMSE_bayeslin,\n",
    "              RMSE_sem,\n",
    "              RMSE_bartsfm,\n",
    "            # RMSE_bartsfm_uadj,\n",
    "              RMSE_bartsfm_beta0\n",
    "  )\n",
    "\n",
    "  BIAS_res <- c(BIAS_bayeslin,\n",
    "                BIAS_sem,\n",
    "                BIAS_bartsfm,\n",
    "                # BIAS_bartsfm_uadj,\n",
    "                BIAS_bartsfm_beta0\n",
    "                # BIAS_bartsfm_beta0_uadj\n",
    "                )\n",
    "\n",
    "  ##############################################################################\n",
    "  # 2. Compare mean bias estimates of sigma_u and sigma_v                           #\n",
    "  ##############################################################################\n",
    "  Bias_sig_v_bayeslin           = abs(median(res_bayes_lin$sigv_post)-sigmav)\n",
    "  Bias_sig_v_sem                = abs(sigma_v_semfit-sigmav)\n",
    "  Bias_sig_v_bartsfm            = abs(median(fitbartsfm$sigma[(nskip+1):(nskip+ndpost)])      -sigmav)\n",
    "  # Bias_sig_v_bartsfm_uadj       = abs(median(fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)]) -sigmav)\n",
    "  Bias_sig_v_bartsfm_beta0      = abs(median(fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)])-sigmav)\n",
    "  # Bias_sig_v_bartsfm_beta0_uadj = abs(median(fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)]) -sigmav)\n",
    "\n",
    "  Bias_sig_u_bayeslin           = abs(median(res_bayes_lin$sigu_post)-sigmau)\n",
    "  Bias_sig_u_sem                = abs(sigma_u_semfit-sigmau)\n",
    "  Bias_sig_u_bartsfm            = abs(median(fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)])     -sigmau)\n",
    "  # Bias_sig_u_bartsfm_uadj       = abs(median(fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)])  -sigmau)\n",
    "  Bias_sig_u_bartsfm_beta0      = abs(median(fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)])  -sigmau)\n",
    "  # Bias_sig_u_bartsfm_beta0_uadj = abs(median(fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)])   -sigmau)\n",
    "\n",
    "  Bias_sig_v_res <- c(\n",
    "      Bias_sig_v_bayeslin      ,\n",
    "      Bias_sig_v_sem           ,\n",
    "      Bias_sig_v_bartsfm       ,\n",
    "      # Bias_sig_v_bartsfm_uadj  ,\n",
    "      Bias_sig_v_bartsfm_beta0\n",
    "      # Bias_sig_v_bartsfm_beta0_uadj\n",
    "    )\n",
    "\n",
    "  Bias_sig_u_res <-\n",
    "    c(Bias_sig_u_bayeslin      ,\n",
    "      Bias_sig_u_sem           ,\n",
    "      Bias_sig_u_bartsfm       ,\n",
    "      # Bias_sig_u_bartsfm_uadj  ,\n",
    "      Bias_sig_u_bartsfm_beta0\n",
    "      # Bias_sig_u_bartsfm_beta0_uadj\n",
    "    )\n",
    "\n",
    "\n",
    "  ##############################################################################\n",
    "  # 3. Compare mean inefficiency scores                                        #\n",
    "  ##############################################################################\n",
    "  #True TEs\n",
    "  res_true<-simdt$y1-(beta0+beta1*simdt$lnx1)\n",
    "  TEvec_true<-sapply(res_true,TE_fun,sigv=sigmav,sigu=sigmau)\n",
    "  mean(TEvec_true)\n",
    "\n",
    "  #Bayes regression TEs\n",
    "  TEvec_bayeslin<-apply(res_bayes_lin,1,function(x){ return(TE_bayes_fun(bayelinres = x,y = simdt$y1,x=simdt$lnx1))})\n",
    "  mean(TEvec_bayeslin)\n",
    "\n",
    "  #TE for sem\n",
    "  res_sem<-simdt$y1-semfit$fitted\n",
    "  TEvec_sem<-sapply(res_sem,TE_fun,sigv=sigma_v_semfit,sigu=sigma_u_semfit)\n",
    "  mean(TEvec_sem)\n",
    "\n",
    "  #TE for bart-sfm\n",
    "  TEvec_bartsfm<-apply(cbind(fitbartsfm$yhat.train,\n",
    "                             fitbartsfm$sigma[(nskip+1):(nskip+ndpost)],\n",
    "                             fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "                       function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "                                                      sigv_post = y[nsamp+1],\n",
    "                                                      sigu_post = y[nsamp+2],\n",
    "                                                      y_bart = simdt$y1\n",
    "                       ))})\n",
    "\n",
    "  #TE for bart-sfm-uadj\n",
    "  # TEvec_bartsfm_uadj<-apply(cbind(fitbartsfm_uadj$yhat.train,\n",
    "  #                                 fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)],\n",
    "  #                                 fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "  #                           function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "  #                                                          sigv_post = y[nsamp+1],\n",
    "  #                                                          sigu_post = y[nsamp+2],\n",
    "  #                                                          y_bart = simdt$y1\n",
    "  #                           ))})\n",
    "\n",
    "  #TE for bart-sfm-beta0\n",
    "  TEvec_bartsfm_beta0<-apply(cbind(fitbartsfm_beta0$yhat.train,\n",
    "                                   fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)],\n",
    "                                   fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "                             function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "                                                            sigv_post = y[nsamp+1],\n",
    "                                                            sigu_post = y[nsamp+2],\n",
    "                                                            y_bart = simdt$y1\n",
    "                             ))})\n",
    "\n",
    "\n",
    "  #TE for bart-sfm-beta0-uadj\n",
    "  # TEvec_bartsfm_beta0_uadj<-apply(cbind(fitbartsfm_beta0_uadj$yhat.train,\n",
    "  #                                       fitbartsfm_beta0_uadj$sigma[(nskip+1):(nskip+ndpost)],\n",
    "  #                                       fitbartsfm_beta0_uadj$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "  #                                 function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "  #                                                                sigv_post = y[nsamp+1],\n",
    "  #                                                                sigu_post = y[nsamp+2],\n",
    "  #                                                                y_bart = simdt$y1\n",
    "  #                                 ))})\n",
    "\n",
    "  TE_bias<-abs(c(\n",
    "    mean(TEvec_bayeslin),\n",
    "    mean(TEvec_sem),\n",
    "    mean(TEvec_bartsfm),\n",
    "    # mean(TEvec_bartsfm_uadj),\n",
    "    mean(TEvec_bartsfm_beta0)\n",
    "    # mean(TEvec_bartsfm_beta0_uadj)\n",
    "  )-mean(TEvec_true))\n",
    "\n",
    "    },\n",
    "  error = function(e) {})\n",
    "}\n",
    "\n",
    "  # TE_bias<-rbind(TE_bias,TE_bias_one)\n",
    "\n",
    "  return(list(RMSE=RMSE_res,\n",
    "              BIAS=BIAS_res,\n",
    "              Bias_sig_v=Bias_sig_v_res,\n",
    "              Bias_sig_u=Bias_sig_u_res,\n",
    "              TE_bias=TE_bias,\n",
    "              simdata=simdt,\n",
    "              sig_v_bart_post=fitbartsfm$sigma,\n",
    "              sig_u_bart_post=fitbartsfm$sigma_u,\n",
    "              sig_v_bart_b0_post=fitbartsfm_beta0$sigma,\n",
    "              sig_u_bart_b0_post=fitbartsfm_beta0$sigma_u\n",
    "              ))\n",
    "\n",
    "}\n",
    "\n",
    "RMSE_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[1]]})))\n",
    "colnames(RMSE_res)<-c(\"RMSE_BayesLin\",\"RMSE_Sem\",\n",
    "                      \"RMSE_Bart\",\n",
    "                      # \"RMSE_Bart_uadj\",\n",
    "                      \"RMSE_Bart_b0\"\n",
    "                      # \"RMSE_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "BIAS_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[2]]})))\n",
    "colnames(BIAS_res)<-c(\"BIAS_BayesLin\",\"BIAS_Sem\",\n",
    "                      \"BIAS_Bart\",\n",
    "                      # \"BIAS_Bart_uadj\",\n",
    "                      \"BIAS_Bart_b0\"\n",
    "                      # \"BIAS_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "Bias_sig_v_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[3]]})))\n",
    "colnames(Bias_sig_v_res)<-c(\"Sigvb_BayesLin\",\"Sigvb_Sem\",\n",
    "                            \"Sigvb_Bart\",\n",
    "                            # \"Sigvb_Bart_uadj\",\n",
    "                            \"Sigvb_Bart_b0\"\n",
    "                            # \"Sigvb_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "Bias_sig_u_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[4]]})))\n",
    "colnames(Bias_sig_u_res)<-c(\"Sigub_BayesLin\",\n",
    "                            \"Sigub_Sem\",\n",
    "                            \"Sigub_Bart\",\n",
    "                            # \"Sigub_Bart_uadj\",\n",
    "                            \"Sigub_Bart_b0\"\n",
    "                            # \"Sigub_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "TE_bias<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[5]]})))\n",
    "colnames(TE_bias)<-c(\"TEb_BayesLin\",\"TEb_Sem\",\n",
    "                     \"TEb_Bart\",\n",
    "                     # \"TEb_Bart_uadj\",\n",
    "                     \"TEb_Bart_b0\"\n",
    "                     # \"TEb_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "resfin<-list(RMSE=RMSE_res,\n",
    "             BIAS=BIAS_res,\n",
    "             Bias_sigv=Bias_sig_v_res,\n",
    "             Bias_sigu=Bias_sig_u_res,\n",
    "             TE_bias=TE_bias,\n",
    "             res=res)\n",
    "saveRDS(resfin, paste(\"res/linear_case_part\",part,\".rds\",sep = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e602a7-73c7-43ea-81ed-de4ea77b91ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R_monbart",
   "language": "R",
   "name": "r4.1.2_monbart"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
