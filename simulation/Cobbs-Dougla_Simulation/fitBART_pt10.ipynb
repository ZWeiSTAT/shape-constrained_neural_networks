{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3dc942-cad4-49a5-abfb-8c2cf4cc8fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘foreach’ was built under R version 4.2.3”\n",
      "Loading required package: iterators\n",
      "\n",
      "Warning message:\n",
      "“package ‘iterators’ was built under R version 4.2.3”\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: micEcon\n",
      "\n",
      "\n",
      "If you have questions, suggestions, or comments regarding one of the 'micEcon' packages, please use a forum or 'tracker' at micEcon's R-Forge site:\n",
      "https://r-forge.r-project.org/projects/micecon/\n",
      "\n",
      "Loading required package: lmtest\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "\n",
      "Please cite the 'frontier' package as:\n",
      "Tim Coelli and Arne Henningsen (2013). frontier: Stochastic Frontier Analysis. R package version 1.1. http://CRAN.R-Project.org/package=frontier.\n",
      "\n",
      "If you have questions, suggestions, or comments regarding the 'frontier' package, please use a forum or 'tracker' at frontier's R-Forge site:\n",
      "https://r-forge.r-project.org/projects/frontier/\n",
      "\n",
      "Loading required package: stats4\n",
      "\n",
      "\n",
      "Attaching package: ‘sn’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    sd\n",
      "\n",
      "\n",
      "Loading required package: mgcv\n",
      "\n",
      "Loading required package: nlme\n",
      "\n",
      "This is mgcv 1.8-41. For overview type 'help(\"mgcv-package\")'.\n",
      "\n",
      "Loading required package: np\n",
      "\n",
      "Warning message:\n",
      "“package ‘np’ was built under R version 4.2.3”\n",
      "Nonparametric Kernel Methods for Mixed Datatypes (version 0.60-17)\n",
      "[vignette(\"np_faq\",package=\"np\") provides answers to frequently asked questions]\n",
      "[vignette(\"np\",package=\"np\") an overview]\n",
      "[vignette(\"entropy_np\",package=\"np\") an overview of entropy-based methods]\n",
      "\n",
      "Loading required package: gamlss\n",
      "\n",
      "Loading required package: splines\n",
      "\n",
      "Loading required package: gamlss.data\n",
      "\n",
      "\n",
      "Attaching package: ‘gamlss.data’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:datasets’:\n",
      "\n",
      "    sleep\n",
      "\n",
      "\n",
      "Loading required package: gamlss.dist\n",
      "\n",
      " **********   GAMLSS Version 5.4-3  ********** \n",
      "\n",
      "For more on GAMLSS look at https://www.gamlss.com/\n",
      "\n",
      "Type gamlssNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rm(list = ls())\n",
    "#setwd('/Users/zhengwei/Desktop/OneDrive - Texas A&M University-Corpus Christi/Research/Huiyan_Sang/DecisionTree/MyPackage/sim1_lin')\n",
    "#setwd(\"/Users/zhengwei/OneDrive - Texas A&M University-Corpus Christi/Research/Huiyan_Sang/DecisionTree/MyPackage/sim1_lin\")\n",
    "\n",
    "library(foreach)\n",
    "library(doMC)\n",
    "library(coda)\n",
    "library(MonBartSFM)\n",
    "library(frontier)\n",
    "library(truncnorm)\n",
    "library(sn)\n",
    "library(MASS)\n",
    "library(semsfa)\n",
    "source(\"otherfuns.R\")\n",
    "source(\"Bayes_SFM_NHN_Gibbs.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfa84ef-70e6-43a7-9dc4-a041485f99a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>log_X</th><th scope=col>log_y</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 2.768552</td><td> 0.2527462</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>-2.856968</td><td>-0.6890037</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>-1.137870</td><td> 0.5694323</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 2.452089</td><td> 2.5354790</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>-1.278954</td><td> 1.4797850</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-1.649340</td><td> 0.2519563</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & log\\_X & log\\_y\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 &  2.768552 &  0.2527462\\\\\n",
       "\t2 & -2.856968 & -0.6890037\\\\\n",
       "\t3 & -1.137870 &  0.5694323\\\\\n",
       "\t4 &  2.452089 &  2.5354790\\\\\n",
       "\t5 & -1.278954 &  1.4797850\\\\\n",
       "\t6 & -1.649340 &  0.2519563\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | log_X &lt;dbl&gt; | log_y &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 |  2.768552 |  0.2527462 |\n",
       "| 2 | -2.856968 | -0.6890037 |\n",
       "| 3 | -1.137870 |  0.5694323 |\n",
       "| 4 |  2.452089 |  2.5354790 |\n",
       "| 5 | -1.278954 |  1.4797850 |\n",
       "| 6 | -1.649340 |  0.2519563 |\n",
       "\n"
      ],
      "text/plain": [
       "  log_X     log_y     \n",
       "1  2.768552  0.2527462\n",
       "2 -2.856968 -0.6890037\n",
       "3 -1.137870  0.5694323\n",
       "4  2.452089  2.5354790\n",
       "5 -1.278954  1.4797850\n",
       "6 -1.649340  0.2519563"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set path to your folder\n",
    "path <- \"simulated_data\"\n",
    "\n",
    "# List all CSV files in that folder\n",
    "files <- list.files(path, pattern = \"\\\\.csv$\", full.names = TRUE)\n",
    "\n",
    "# Read each CSV into a list of data.frames\n",
    "simulated_datasets_R <- lapply(files, read.csv)\n",
    "\n",
    "# Access the first dataset\n",
    "head(simulated_datasets_R[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6104df-bd6e-4587-9a42-6a1902d2d3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  91 \n",
      "Cumulative average: iter= 1000 beta0= 0.6477 beta= 0.1921 sigmav= 0.8631 sigmau= 0.2809 \n",
      "Cumulative average: iter= 2000 beta0= 0.6444 beta= 0.1924 sigmav= 0.8647 sigmau= 0.279 \n",
      "Cumulative average: iter= 3000 beta0= 0.6499 beta= 0.1919 sigmav= 0.8629 sigmau= 0.2867 \n",
      "Cumulative average: iter= 4000 beta0= 0.6593 beta= 0.1919 sigmav= 0.8603 sigmau= 0.2984 \n",
      "Cumulative average: iter= 5000 beta0= 0.6616 beta= 0.1919 sigmav= 0.858 sigmau= 0.3015 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -2.174458, -1.234184\n",
      "first row: -2.058907, -2.058907\n",
      "second row: 1.757851, 1.757851\n",
      "last row: 0.560444, 0.560444\n",
      "no test observations\n",
      "tau: 0.137754\n",
      "nu: 3.000000\n",
      "lambda: 0.049269\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.941084 ... 2.873066\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -2.174458, -1.234184\n",
      "first row: -2.058907, -2.058907\n",
      "second row: 1.757851, 1.757851\n",
      "last row: 0.560444, 0.560444\n",
      "no test observations\n",
      "tau: 0.137754\n",
      "nu: 3.000000\n",
      "lambda: 0.049269\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.941084 ... 2.873066\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  92 \n",
      "Cumulative average: iter= 1000 beta0= 0.8042 beta= 0.2015 sigmav= 0.9336 sigmau= 0.3687 \n",
      "Cumulative average: iter= 2000 beta0= 0.76 beta= 0.2028 sigmav= 0.9451 sigmau= 0.3142 \n",
      "Cumulative average: iter= 3000 beta0= 0.7494 beta= 0.203 sigmav= 0.9473 sigmau= 0.3008 \n",
      "Cumulative average: iter= 4000 beta0= 0.7481 beta= 0.2025 sigmav= 0.9468 sigmau= 0.299 \n",
      "Cumulative average: iter= 5000 beta0= 0.7674 beta= 0.2024 sigmav= 0.9428 sigmau= 0.3232 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.865800, 0.667090\n",
      "first row: 2.766518, 2.766518\n",
      "second row: 1.549928, 1.549928\n",
      "last row: 1.777340, 1.777340\n",
      "no test observations\n",
      "tau: 0.164957\n",
      "nu: 3.000000\n",
      "lambda: 0.080883\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.940238 ... 2.896818\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.865800, 0.667090\n",
      "first row: 2.766518, 2.766518\n",
      "second row: 1.549928, 1.549928\n",
      "last row: 1.777340, 1.777340\n",
      "no test observations\n",
      "tau: 0.164957\n",
      "nu: 3.000000\n",
      "lambda: 0.080883\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.940238 ... 2.896818\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  93 \n",
      "Cumulative average: iter= 1000 beta0= 0.7722 beta= 0.2114 sigmav= 0.8379 sigmau= 0.2589 \n",
      "Cumulative average: iter= 2000 beta0= 0.7687 beta= 0.2105 sigmav= 0.8396 sigmau= 0.2551 \n",
      "Cumulative average: iter= 3000 beta0= 0.7828 beta= 0.2106 sigmav= 0.8362 sigmau= 0.2722 \n",
      "Cumulative average: iter= 4000 beta0= 0.7901 beta= 0.2104 sigmav= 0.8355 sigmau= 0.2819 \n",
      "Cumulative average: iter= 5000 beta0= 0.7938 beta= 0.2107 sigmav= 0.8344 sigmau= 0.2859 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.182674, -0.400985\n",
      "first row: 2.442453, 2.442453\n",
      "second row: 1.070789, 1.070789\n",
      "last row: 1.360736, 1.360736\n",
      "no test observations\n",
      "tau: 0.143090\n",
      "nu: 3.000000\n",
      "lambda: 0.047033\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.895129 ... 2.900777\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.182674, -0.400985\n",
      "first row: 2.442453, 2.442453\n",
      "second row: 1.070789, 1.070789\n",
      "last row: 1.360736, 1.360736\n",
      "no test observations\n",
      "tau: 0.143090\n",
      "nu: 3.000000\n",
      "lambda: 0.047033\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.895129 ... 2.900777\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  94 \n",
      "Cumulative average: iter= 1000 beta0= 0.8824 beta= 0.215 sigmav= 0.9268 sigmau= 0.2842 \n",
      "Cumulative average: iter= 2000 beta0= 0.8665 beta= 0.2144 sigmav= 0.9298 sigmau= 0.2639 \n",
      "Cumulative average: iter= 3000 beta0= 0.865 beta= 0.2146 sigmav= 0.93 sigmau= 0.2624 \n",
      "Cumulative average: iter= 4000 beta0= 0.8775 beta= 0.2141 sigmav= 0.9282 sigmau= 0.2773 \n",
      "Cumulative average: iter= 5000 beta0= 0.8761 beta= 0.2135 sigmav= 0.9287 sigmau= 0.2757 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.587576, -0.289072\n",
      "first row: -0.233074, -0.233074\n",
      "second row: 1.566477, 1.566477\n",
      "last row: 0.304909, 0.304909\n",
      "no test observations\n",
      "tau: 0.161115\n",
      "nu: 3.000000\n",
      "lambda: 0.079925\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.898220 ... 2.937075\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.587576, -0.289072\n",
      "first row: -0.233074, -0.233074\n",
      "second row: 1.566477, 1.566477\n",
      "last row: 0.304909, 0.304909\n",
      "no test observations\n",
      "tau: 0.161115\n",
      "nu: 3.000000\n",
      "lambda: 0.079925\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.898220 ... 2.937075\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  95 \n",
      "Cumulative average: iter= 1000 beta0= 0.776 beta= 0.1473 sigmav= 0.9226 sigmau= 0.2888 \n",
      "Cumulative average: iter= 2000 beta0= 0.7576 beta= 0.1479 sigmav= 0.9262 sigmau= 0.2661 \n",
      "Cumulative average: iter= 3000 beta0= 0.7604 beta= 0.1481 sigmav= 0.9266 sigmau= 0.2693 \n",
      "Cumulative average: iter= 4000 beta0= 0.7648 beta= 0.1479 sigmav= 0.9262 sigmau= 0.2743 \n",
      "Cumulative average: iter= 5000 beta0= 0.7649 beta= 0.1478 sigmav= 0.9265 sigmau= 0.2744 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.112835, 0.559181\n",
      "first row: -0.454314, -0.454314\n",
      "second row: 0.192975, 0.192975\n",
      "last row: 0.618346, 0.618346\n",
      "no test observations\n",
      "tau: 0.170545\n",
      "nu: 3.000000\n",
      "lambda: 0.101565\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.895383 ... 2.868663\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.112835, 0.559181\n",
      "first row: -0.454314, -0.454314\n",
      "second row: 0.192975, 0.192975\n",
      "last row: 0.618346, 0.618346\n",
      "no test observations\n",
      "tau: 0.170545\n",
      "nu: 3.000000\n",
      "lambda: 0.101565\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.895383 ... 2.868663\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  96 \n",
      "Cumulative average: iter= 1000 beta0= 0.7155 beta= 0.2514 sigmav= 0.9019 sigmau= 0.2732 \n",
      "Cumulative average: iter= 2000 beta0= 0.7168 beta= 0.2517 sigmav= 0.9015 sigmau= 0.2755 \n",
      "Cumulative average: iter= 3000 beta0= 0.7166 beta= 0.2519 sigmav= 0.9017 sigmau= 0.2745 \n",
      "Cumulative average: iter= 4000 beta0= 0.7205 beta= 0.2516 sigmav= 0.901 sigmau= 0.2787 \n",
      "Cumulative average: iter= 5000 beta0= 0.7219 beta= 0.2516 sigmav= 0.9011 sigmau= 0.28 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 2.326195, 0.350033\n",
      "first row: 2.197827, 2.197827\n",
      "second row: 2.496542, 2.496542\n",
      "last row: -0.095950, -0.095950\n",
      "no test observations\n",
      "tau: 0.164808\n",
      "nu: 3.000000\n",
      "lambda: 0.096324\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.901245 ... 2.925024\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 2.326195, 0.350033\n",
      "first row: 2.197827, 2.197827\n",
      "second row: 2.496542, 2.496542\n",
      "last row: -0.095950, -0.095950\n",
      "no test observations\n",
      "tau: 0.164808\n",
      "nu: 3.000000\n",
      "lambda: 0.096324\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.901245 ... 2.925024\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  97 \n",
      "Cumulative average: iter= 1000 beta0= 0.8463 beta= 0.2062 sigmav= 0.8924 sigmau= 0.3686 \n",
      "Cumulative average: iter= 2000 beta0= 0.8187 beta= 0.2056 sigmav= 0.8988 sigmau= 0.334 \n",
      "Cumulative average: iter= 3000 beta0= 0.82 beta= 0.206 sigmav= 0.9004 sigmau= 0.335 \n",
      "Cumulative average: iter= 4000 beta0= 0.8038 beta= 0.2067 sigmav= 0.9037 sigmau= 0.3147 \n",
      "Cumulative average: iter= 5000 beta0= 0.8057 beta= 0.2067 sigmav= 0.9032 sigmau= 0.3155 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.677774, -0.398295\n",
      "first row: -2.897177, -2.897177\n",
      "second row: -2.740682, -2.740682\n",
      "last row: 0.877285, 0.877285\n",
      "no test observations\n",
      "tau: 0.182311\n",
      "nu: 3.000000\n",
      "lambda: 0.064416\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.883876 ... 2.886419\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.677774, -0.398295\n",
      "first row: -2.897177, -2.897177\n",
      "second row: -2.740682, -2.740682\n",
      "last row: 0.877285, 0.877285\n",
      "no test observations\n",
      "tau: 0.182311\n",
      "nu: 3.000000\n",
      "lambda: 0.064416\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.883876 ... 2.886419\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  98 \n",
      "Cumulative average: iter= 1000 beta0= 0.6616 beta= 0.1823 sigmav= 0.8997 sigmau= 0.2536 \n",
      "Cumulative average: iter= 2000 beta0= 0.6607 beta= 0.1816 sigmav= 0.8986 sigmau= 0.2538 \n",
      "Cumulative average: iter= 3000 beta0= 0.6529 beta= 0.182 sigmav= 0.8993 sigmau= 0.2451 \n",
      "Cumulative average: iter= 4000 beta0= 0.6629 beta= 0.1816 sigmav= 0.8982 sigmau= 0.2568 \n",
      "Cumulative average: iter= 5000 beta0= 0.664 beta= 0.1824 sigmav= 0.8979 sigmau= 0.2583 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.350146, 1.377438\n",
      "first row: -2.256060, -2.256060\n",
      "second row: -2.244629, -2.244629\n",
      "last row: 2.267111, 2.267111\n",
      "no test observations\n",
      "tau: 0.166566\n",
      "nu: 3.000000\n",
      "lambda: 0.094675\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.884059 ... 2.910237\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.350146, 1.377438\n",
      "first row: -2.256060, -2.256060\n",
      "second row: -2.244629, -2.244629\n",
      "last row: 2.267111, 2.267111\n",
      "no test observations\n",
      "tau: 0.166566\n",
      "nu: 3.000000\n",
      "lambda: 0.094675\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.884059 ... 2.910237\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  99 \n",
      "Cumulative average: iter= 1000 beta0= 0.7772 beta= 0.1801 sigmav= 0.8833 sigmau= 0.2798 \n",
      "Cumulative average: iter= 2000 beta0= 0.7571 beta= 0.1797 sigmav= 0.8867 sigmau= 0.254 \n",
      "Cumulative average: iter= 3000 beta0= 0.7884 beta= 0.1799 sigmav= 0.8817 sigmau= 0.2908 \n",
      "Cumulative average: iter= 4000 beta0= 0.782 beta= 0.1795 sigmav= 0.8831 sigmau= 0.2832 \n",
      "Cumulative average: iter= 5000 beta0= 0.7882 beta= 0.1797 sigmav= 0.8829 sigmau= 0.2916 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 2.214284, 0.971469\n",
      "first row: -2.068001, -2.068001\n",
      "second row: -0.866369, -0.866369\n",
      "last row: 2.490132, 2.490132\n",
      "no test observations\n",
      "tau: 0.163857\n",
      "nu: 3.000000\n",
      "lambda: 0.092739\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.935964 ... 2.919220\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 2.214284, 0.971469\n",
      "first row: -2.068001, -2.068001\n",
      "second row: -0.866369, -0.866369\n",
      "last row: 2.490132, 2.490132\n",
      "no test observations\n",
      "tau: 0.163857\n",
      "nu: 3.000000\n",
      "lambda: 0.092739\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.935964 ... 2.919220\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  100 \n",
      "Cumulative average: iter= 1000 beta0= 0.7481 beta= 0.1993 sigmav= 0.9308 sigmau= 0.2913 \n",
      "Cumulative average: iter= 2000 beta0= 0.7454 beta= 0.1994 sigmav= 0.9308 sigmau= 0.287 \n",
      "Cumulative average: iter= 3000 beta0= 0.7528 beta= 0.1983 sigmav= 0.9301 sigmau= 0.2944 \n",
      "Cumulative average: iter= 4000 beta0= 0.7571 beta= 0.1985 sigmav= 0.9288 sigmau= 0.2998 \n",
      "Cumulative average: iter= 5000 beta0= 0.7543 beta= 0.1983 sigmav= 0.929 sigmau= 0.2973 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.991270, 1.490841\n",
      "first row: -2.810254, -2.810254\n",
      "second row: -2.505043, -2.505043\n",
      "last row: 1.608277, 1.608277\n",
      "no test observations\n",
      "tau: 0.177503\n",
      "nu: 3.000000\n",
      "lambda: 0.102975\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.927969 ... 2.904253\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.991270, 1.490841\n",
      "first row: -2.810254, -2.810254\n",
      "second row: -2.505043, -2.505043\n",
      "last row: 1.608277, 1.608277\n",
      "no test observations\n",
      "tau: 0.177503\n",
      "nu: 3.000000\n",
      "lambda: 0.102975\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.927969 ... 2.904253\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n"
     ]
    }
   ],
   "source": [
    "#set cores for parallel computing\n",
    "RNGkind(\"L'Ecuyer-CMRG\")\n",
    "cores<-strtoi(Sys.getenv('SLURM_CPUS_PER_TASK', unset=1))\n",
    "registerDoMC(cores)\n",
    "\n",
    "part=10\n",
    "\n",
    "res<-foreach(i=91:100) %dopar% {\n",
    "  cat(\"i= \",i,'\\n')\n",
    "\n",
    "finished <- FALSE\n",
    "while(!finished) {\n",
    "    tryCatch({\n",
    "\n",
    "  ##########################################\n",
    "  #    simulate data for linear case       #\n",
    "  ##########################################\n",
    "  ## simulate simple data with one x\n",
    "  beta0=log(2)\n",
    "  beta1=0.2\n",
    "  sigmav=0.9\n",
    "  sigmau=0.2\n",
    "  nsamp=200\n",
    "\n",
    "  x_org=simulated_datasets_R[[i]]$log_X\n",
    "  y_org=simulated_datasets_R[[i]]$log_y\n",
    "\n",
    "\n",
    "  ########################################\n",
    "  # Model 1 fit the Bayes Linear Model\n",
    "  ########################################\n",
    "\n",
    "  simdt=data.frame(y1=y_org,lnx1=x_org)\n",
    "\n",
    "  B_burnin=1000\n",
    "  B_afterburnin=4000\n",
    "\n",
    "  # B_burnin=2\n",
    "  # B_afterburnin=20\n",
    "\n",
    "  res_Bayelin<-Bayeslinear_NHN_fit(B_burnin,\n",
    "                                   B_afterburnin,\n",
    "                                   simdt,\n",
    "                                   beta0_init = 0,\n",
    "                                   beta_init=beta0,\n",
    "                                   sigu_init=sigmau,\n",
    "                                   sigv_init=sigmav,\n",
    "                                   df_v = 5,\n",
    "                                   S_v =(5+2)*sigmav^2,\n",
    "                                   df_u =5,\n",
    "                                   S_u = (5+2)*sigmau^2)\n",
    "\n",
    "\n",
    "  B=B_burnin+B_afterburnin\n",
    "  res_bayes_lin<-na.omit(res_Bayelin$res[B_burnin+1:B,])\n",
    "\n",
    "  ##############################################\n",
    "  # Model 2\n",
    "  # fit SEM-SFM\n",
    "  # imposing monotonicity restrictions on inputs\n",
    "  ##############################################\n",
    "  #first-step: monotone gam, second-step: fan\n",
    "  dati=data.frame(y=y_org,x=x_org)\n",
    "  semfit<-semsfa(y~pbm(x,mono=\"up\"),sem.method = \"gam.mono\",dati)\n",
    "  sigma_v_semfit=sqrt(semfit$sigma^2/(1+semfit$lambda^2))\n",
    "  sigma_u_semfit=semfit$lambda*sigma_v_semfit\n",
    "\n",
    "  ##############################################\n",
    "  # Model 3\n",
    "  # fit Mon-BART-SFM\n",
    "  # imposing monotonicity restrictions on inputs\n",
    "  ##############################################\n",
    "  #find initial value for sigma_v and sigma_u\n",
    "\n",
    "  fit_sfa <-sfa( y1 ~ lnx1,data = simdt)\n",
    "  gamma <- unname( coef(fit_sfa)[\"gamma\"] )\n",
    "  sigmaSq <- unname( coef(fit_sfa)[\"sigmaSq\"] )\n",
    "  sigmaSqU <- gamma * sigmaSq\n",
    "  sigmaSqV <- ( 1 - gamma ) * sigmaSq\n",
    "  betavec<-coef(fit_sfa)[1:3]\n",
    "  sigma_u<-sqrt(sigmaSqU)\n",
    "  sigma_v<-sqrt(sigmaSqV)\n",
    "\n",
    "\n",
    "\n",
    "  ysnfit<-selm(y_org ~ 1, family=\"SN\")\n",
    "  center_Y <- ysnfit@param$dp[1]\n",
    "\n",
    "  nskip=B_burnin\n",
    "  ndpost=B_afterburnin\n",
    "\n",
    "\n",
    "  fitbartsfm<-monbartsfm(\n",
    "    x.train=as.matrix(x_org),y.train=y_org, x.test=matrix(0.0,0,0),\n",
    "    sigest=sigma_v,\n",
    "    sigdf=3,\n",
    "    sigquant=.95,\n",
    "    sigu_pre_est=sigma_u,\n",
    "    sigquant_u=.95,\n",
    "    k=2.0,\n",
    "    power=.8, base=.25, #regular bart is 2,.95\n",
    "    sigmaf=NA,\n",
    "    lambda=NA,\n",
    "    fmean = center_Y,\n",
    "    #fscale=scale_Y,\n",
    "    ntree=100,\n",
    "    ndpost, nskip,\n",
    "    mgsize=50,\n",
    "    nkeeptrain=ndpost,nkeeptest=ndpost,\n",
    "    nkeeptestmean=ndpost,\n",
    "    nkeeptreedraws=ndpost,\n",
    "    printevery=100\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  fitbartsfm_beta0<-monbartsfm_beta0(\n",
    "    x.train=as.matrix(x_org),y.train=y_org, x.test=matrix(0.0,0,0),\n",
    "    sigest=sigma_v,\n",
    "    sigdf=3,\n",
    "    sigquant=.95,\n",
    "    sigu_pre_est=sigma_u,\n",
    "    sigquant_u=.95,\n",
    "    k=2.0,\n",
    "    power=.8, base=.25, #regular bart is 2,.95\n",
    "    sigmaf=NA,\n",
    "    lambda=NA,\n",
    "    fmean = center_Y,\n",
    "    #fscale=scale_Y,\n",
    "    ntree=100,\n",
    "    ndpost, nskip,\n",
    "    mgsize=50,\n",
    "    nkeeptrain=ndpost,nkeeptest=ndpost,\n",
    "    nkeeptestmean=ndpost,\n",
    "    nkeeptreedraws=ndpost,\n",
    "    printevery=100\n",
    "  )\n",
    "\n",
    "  gtest<-geweke.diag(fitbartsfm$sigma_u)\n",
    "  pval_BART<-1-pnorm(gtest$z)\n",
    "  # pval_BART=0.5\n",
    "  gtest_b0<-geweke.diag(fitbartsfm_beta0$sigma_u)\n",
    "  pval_BART_b0<-1-pnorm(gtest_b0$z)\n",
    "  # pval_BART_b0=0.5\n",
    "  finished <- TRUE #if convergence test is passed, then next iteration\n",
    "\n",
    "  if(pval_BART>0.1&pval_BART_b0>0.1){\n",
    "    finished <- TRUE #if convergence test is passed, then next iteration\n",
    "  }\n",
    "\n",
    "  #######################################\n",
    "  # 1. Compare RMSE and BIAS            #\n",
    "  #######################################\n",
    "\n",
    "  y_tf = exp(beta0)*exp(x_org)^beta1 #((X**w_true)*b_true).numpy() \n",
    "  #############################################################################\n",
    "  #formulas are from Eq. 10 and 11 from                                       #\n",
    "  #Ferrara and Vidoli 2017 Semiparametric Stochastic frontier models          #\n",
    "  #############################################################################\n",
    "    \n",
    "  RMSE_bayeslin           = 0 #mean(((mean(res_Bayelin$res$beta0_post)+mean(res_Bayelin$res$beta_current)*x_org-y_org)/y_org)^2) # I did not calculate the Bayes lin\n",
    "  # e_sem = y_org - (semfit$fitted)\n",
    "  # E_sem_correction = mean(exp(e_sem))\n",
    "\n",
    "  E_sem_correction = exp((sigma_v_semfit**2+sigma_u_semfit**2)/2)    \n",
    "  RMSE_sem         = mean(((exp(semfit$fitted)*E_sem_correction-y_tf)/y_tf)^2)\n",
    "  # e_bartsfm = y_org - (fitbartsfm$yhat.train.mean)\n",
    "  # E_bartsfm_correction = mean(exp(e_bartsfm))\n",
    "  sigv_map = median(fitbartsfm$sigma[(nskip+1):(nskip+ndpost)])\n",
    "  sigu_map = median(fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)])\n",
    "  \n",
    "  E_bartsfm_correction =  exp((sigv_map**2+sigv_map**2)/2)    \n",
    "  RMSE_bartsfm            =mean(((exp(fitbartsfm$yhat.train.mean)*E_bartsfm_correction-y_tf)/y_tf)^2)\n",
    "        \n",
    "  # RMSE_bartsfm_uadj       =mean(((fitbartsfm_uadj$yhat.train.mean-y_org)/y_org)^2)\n",
    "  # e_bartsfm_beta0 = y_org - (fitbartsfm_beta0$yhat.train.mean)\n",
    "  # E_bartsfm_beta0_correction = mean(exp(e_bartsfm_beta0))\n",
    "  sigv_beta0_map = median(fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)])\n",
    "  sigu_beta0_map = median(fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)])\n",
    "\n",
    "  E_bartsfm_beta0_correction = exp((sigv_beta0_map**2+sigu_beta0_map**2)/2)   \n",
    "  RMSE_bartsfm_beta0      =mean(((exp(fitbartsfm_beta0$yhat.train.mean)*E_bartsfm_beta0_correction-y_tf)/y_tf)^2)\n",
    "  # RMSE_bartsfm_beta0_uadj =mean(((fitbartsfm_beta0_uadj$yhat.train.mean-y_org)/y_org)^2)\n",
    "\n",
    "  BIAS_bayeslin           =mean(abs((mean(res_Bayelin$res$beta0_post)+mean(res_Bayelin$res$beta_current)*x_org-y_org)/y_org))\n",
    "  BIAS_sem                =mean(abs((exp(semfit$fitted)*E_sem_correction-y_tf)/y_tf))\n",
    "  BIAS_bartsfm            =mean(abs((exp(fitbartsfm$yhat.train.mean)*E_bartsfm_correction-y_tf)/y_tf))\n",
    "  # BIAS_bartsfm_uadj       =median(((fitbartsfm_uadj$yhat.train.mean-y_org)/y_org))\n",
    "  BIAS_bartsfm_beta0      =median(abs((exp(fitbartsfm_beta0$yhat.train.mean)*E_bartsfm_beta0_correction-y_tf)/y_tf))\n",
    "  # BIAS_bartsfm_beta0_uadj =median(((fitbartsfm_beta0_uadj$yhat.train.mean-y_org)/y_org))\n",
    "\n",
    "  RMSE_res<-c(RMSE_bayeslin,\n",
    "              RMSE_sem,\n",
    "              RMSE_bartsfm,\n",
    "            # RMSE_bartsfm_uadj,\n",
    "              RMSE_bartsfm_beta0\n",
    "  )\n",
    "\n",
    "  BIAS_res <- c(BIAS_bayeslin,\n",
    "                BIAS_sem,\n",
    "                BIAS_bartsfm,\n",
    "                # BIAS_bartsfm_uadj,\n",
    "                BIAS_bartsfm_beta0\n",
    "                # BIAS_bartsfm_beta0_uadj\n",
    "                )\n",
    "\n",
    "  ##############################################################################\n",
    "  # 2. Compare mean bias estimates of sigma_u and sigma_v                           #\n",
    "  ##############################################################################\n",
    "  Bias_sig_v_bayeslin           = abs(median(res_bayes_lin$sigv_post)-sigmav)\n",
    "  Bias_sig_v_sem                = abs(sigma_v_semfit-sigmav)\n",
    "  Bias_sig_v_bartsfm            = abs(median(fitbartsfm$sigma[(nskip+1):(nskip+ndpost)])      -sigmav)\n",
    "  # Bias_sig_v_bartsfm_uadj       = abs(median(fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)]) -sigmav)\n",
    "  Bias_sig_v_bartsfm_beta0      = abs(median(fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)])-sigmav)\n",
    "  # Bias_sig_v_bartsfm_beta0_uadj = abs(median(fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)]) -sigmav)\n",
    "\n",
    "  Bias_sig_u_bayeslin           = abs(median(res_bayes_lin$sigu_post)-sigmau)\n",
    "  Bias_sig_u_sem                = abs(sigma_u_semfit-sigmau)\n",
    "  Bias_sig_u_bartsfm            = abs(median(fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)])     -sigmau)\n",
    "  # Bias_sig_u_bartsfm_uadj       = abs(median(fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)])  -sigmau)\n",
    "  Bias_sig_u_bartsfm_beta0      = abs(median(fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)])  -sigmau)\n",
    "  # Bias_sig_u_bartsfm_beta0_uadj = abs(median(fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)])   -sigmau)\n",
    "\n",
    "  Bias_sig_v_res <- c(\n",
    "      Bias_sig_v_bayeslin      ,\n",
    "      Bias_sig_v_sem           ,\n",
    "      Bias_sig_v_bartsfm       ,\n",
    "      # Bias_sig_v_bartsfm_uadj  ,\n",
    "      Bias_sig_v_bartsfm_beta0\n",
    "      # Bias_sig_v_bartsfm_beta0_uadj\n",
    "    )\n",
    "\n",
    "  Bias_sig_u_res <-\n",
    "    c(Bias_sig_u_bayeslin      ,\n",
    "      Bias_sig_u_sem           ,\n",
    "      Bias_sig_u_bartsfm       ,\n",
    "      # Bias_sig_u_bartsfm_uadj  ,\n",
    "      Bias_sig_u_bartsfm_beta0\n",
    "      # Bias_sig_u_bartsfm_beta0_uadj\n",
    "    )\n",
    "\n",
    "\n",
    "  ##############################################################################\n",
    "  # 3. Compare mean inefficiency scores                                        #\n",
    "  ##############################################################################\n",
    "  #True TEs\n",
    "  res_true<-simdt$y1-(beta0+beta1*simdt$lnx1)\n",
    "  TEvec_true<-sapply(res_true,TE_fun,sigv=sigmav,sigu=sigmau)\n",
    "  mean(TEvec_true)\n",
    "\n",
    "  #Bayes regression TEs\n",
    "  TEvec_bayeslin<-apply(res_bayes_lin,1,function(x){ return(TE_bayes_fun(bayelinres = x,y = simdt$y1,x=simdt$lnx1))})\n",
    "  mean(TEvec_bayeslin)\n",
    "\n",
    "  #TE for sem\n",
    "  res_sem<-simdt$y1-semfit$fitted\n",
    "  TEvec_sem<-sapply(res_sem,TE_fun,sigv=sigma_v_semfit,sigu=sigma_u_semfit)\n",
    "  mean(TEvec_sem)\n",
    "\n",
    "  #TE for bart-sfm\n",
    "  TEvec_bartsfm<-apply(cbind(fitbartsfm$yhat.train,\n",
    "                             fitbartsfm$sigma[(nskip+1):(nskip+ndpost)],\n",
    "                             fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "                       function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "                                                      sigv_post = y[nsamp+1],\n",
    "                                                      sigu_post = y[nsamp+2],\n",
    "                                                      y_bart = simdt$y1\n",
    "                       ))})\n",
    "\n",
    "  #TE for bart-sfm-uadj\n",
    "  # TEvec_bartsfm_uadj<-apply(cbind(fitbartsfm_uadj$yhat.train,\n",
    "  #                                 fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)],\n",
    "  #                                 fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "  #                           function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "  #                                                          sigv_post = y[nsamp+1],\n",
    "  #                                                          sigu_post = y[nsamp+2],\n",
    "  #                                                          y_bart = simdt$y1\n",
    "  #                           ))})\n",
    "\n",
    "  #TE for bart-sfm-beta0\n",
    "  TEvec_bartsfm_beta0<-apply(cbind(fitbartsfm_beta0$yhat.train,\n",
    "                                   fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)],\n",
    "                                   fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "                             function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "                                                            sigv_post = y[nsamp+1],\n",
    "                                                            sigu_post = y[nsamp+2],\n",
    "                                                            y_bart = simdt$y1\n",
    "                             ))})\n",
    "\n",
    "\n",
    "  #TE for bart-sfm-beta0-uadj\n",
    "  # TEvec_bartsfm_beta0_uadj<-apply(cbind(fitbartsfm_beta0_uadj$yhat.train,\n",
    "  #                                       fitbartsfm_beta0_uadj$sigma[(nskip+1):(nskip+ndpost)],\n",
    "  #                                       fitbartsfm_beta0_uadj$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "  #                                 function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "  #                                                                sigv_post = y[nsamp+1],\n",
    "  #                                                                sigu_post = y[nsamp+2],\n",
    "  #                                                                y_bart = simdt$y1\n",
    "  #                                 ))})\n",
    "\n",
    "  TE_bias<-abs(c(\n",
    "    mean(TEvec_bayeslin),\n",
    "    mean(TEvec_sem),\n",
    "    mean(TEvec_bartsfm),\n",
    "    # mean(TEvec_bartsfm_uadj),\n",
    "    mean(TEvec_bartsfm_beta0)\n",
    "    # mean(TEvec_bartsfm_beta0_uadj)\n",
    "  )-mean(TEvec_true))\n",
    "\n",
    "    },\n",
    "  error = function(e) {})\n",
    "}\n",
    "\n",
    "  # TE_bias<-rbind(TE_bias,TE_bias_one)\n",
    "\n",
    "  return(list(RMSE=RMSE_res,\n",
    "              BIAS=BIAS_res,\n",
    "              Bias_sig_v=Bias_sig_v_res,\n",
    "              Bias_sig_u=Bias_sig_u_res,\n",
    "              TE_bias=TE_bias,\n",
    "              simdata=simdt,\n",
    "              sig_v_bart_post=fitbartsfm$sigma,\n",
    "              sig_u_bart_post=fitbartsfm$sigma_u,\n",
    "              sig_v_bart_b0_post=fitbartsfm_beta0$sigma,\n",
    "              sig_u_bart_b0_post=fitbartsfm_beta0$sigma_u\n",
    "              ))\n",
    "\n",
    "}\n",
    "\n",
    "RMSE_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[1]]})))\n",
    "colnames(RMSE_res)<-c(\"RMSE_BayesLin\",\"RMSE_Sem\",\n",
    "                      \"RMSE_Bart\",\n",
    "                      # \"RMSE_Bart_uadj\",\n",
    "                      \"RMSE_Bart_b0\"\n",
    "                      # \"RMSE_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "BIAS_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[2]]})))\n",
    "colnames(BIAS_res)<-c(\"BIAS_BayesLin\",\"BIAS_Sem\",\n",
    "                      \"BIAS_Bart\",\n",
    "                      # \"BIAS_Bart_uadj\",\n",
    "                      \"BIAS_Bart_b0\"\n",
    "                      # \"BIAS_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "Bias_sig_v_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[3]]})))\n",
    "colnames(Bias_sig_v_res)<-c(\"Sigvb_BayesLin\",\"Sigvb_Sem\",\n",
    "                            \"Sigvb_Bart\",\n",
    "                            # \"Sigvb_Bart_uadj\",\n",
    "                            \"Sigvb_Bart_b0\"\n",
    "                            # \"Sigvb_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "Bias_sig_u_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[4]]})))\n",
    "colnames(Bias_sig_u_res)<-c(\"Sigub_BayesLin\",\n",
    "                            \"Sigub_Sem\",\n",
    "                            \"Sigub_Bart\",\n",
    "                            # \"Sigub_Bart_uadj\",\n",
    "                            \"Sigub_Bart_b0\"\n",
    "                            # \"Sigub_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "TE_bias<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[5]]})))\n",
    "colnames(TE_bias)<-c(\"TEb_BayesLin\",\"TEb_Sem\",\n",
    "                     \"TEb_Bart\",\n",
    "                     # \"TEb_Bart_uadj\",\n",
    "                     \"TEb_Bart_b0\"\n",
    "                     # \"TEb_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "resfin<-list(RMSE=RMSE_res,\n",
    "             BIAS=BIAS_res,\n",
    "             Bias_sigv=Bias_sig_v_res,\n",
    "             Bias_sigu=Bias_sig_u_res,\n",
    "             TE_bias=TE_bias,\n",
    "             res=res)\n",
    "saveRDS(resfin, paste(\"res/linear_case_part\",part,\".rds\",sep = \"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R_monbart",
   "language": "R",
   "name": "r4.1.2_monbart"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
