{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500e42e-211b-4960-a2bd-8b767c374d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 1/100 ---\n",
      "\n",
      "--- Simulation run 2/100 ---\n",
      "\n",
      "--- Simulation run 3/100 ---\n",
      "\n",
      "--- Simulation run 4/100 ---\n",
      "\n",
      "--- Simulation run 5/100 ---\n",
      "\n",
      "--- Simulation run 6/100 ---\n",
      "\n",
      "--- Simulation run 7/100 ---\n",
      "\n",
      "--- Simulation run 8/100 ---\n",
      "\n",
      "--- Simulation run 9/100 ---\n",
      "\n",
      "--- Simulation run 10/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 11/100 ---\n",
      "\n",
      "--- Simulation run 12/100 ---\n",
      "\n",
      "--- Simulation run 13/100 ---\n",
      "\n",
      "--- Simulation run 14/100 ---\n",
      "\n",
      "--- Simulation run 15/100 ---\n",
      "\n",
      "--- Simulation run 16/100 ---\n",
      "\n",
      "--- Simulation run 17/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 18/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 19/100 ---\n",
      "\n",
      "--- Simulation run 20/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 21/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 22/100 ---\n",
      "\n",
      "--- Simulation run 23/100 ---\n",
      "\n",
      "--- Simulation run 24/100 ---\n",
      "\n",
      "--- Simulation run 25/100 ---\n",
      "\n",
      "--- Simulation run 26/100 ---\n",
      "\n",
      "--- Simulation run 27/100 ---\n",
      "\n",
      "--- Simulation run 28/100 ---\n",
      "\n",
      "--- Simulation run 29/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 30/100 ---\n",
      "\n",
      "--- Simulation run 31/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 32/100 ---\n",
      "\n",
      "--- Simulation run 33/100 ---\n",
      "\n",
      "--- Simulation run 34/100 ---\n",
      "\n",
      "--- Simulation run 35/100 ---\n",
      "\n",
      "--- Simulation run 36/100 ---\n",
      "\n",
      "--- Simulation run 37/100 ---\n",
      "\n",
      "--- Simulation run 38/100 ---\n",
      "\n",
      "--- Simulation run 39/100 ---\n",
      "\n",
      "--- Simulation run 40/100 ---\n",
      "\n",
      "--- Simulation run 41/100 ---\n",
      "\n",
      "--- Simulation run 42/100 ---\n",
      "\n",
      "--- Simulation run 43/100 ---\n",
      "\n",
      "--- Simulation run 44/100 ---\n",
      "\n",
      "--- Simulation run 45/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 46/100 ---\n",
      "\n",
      "--- Simulation run 47/100 ---\n",
      "\n",
      "--- Simulation run 48/100 ---\n",
      "\n",
      "--- Simulation run 49/100 ---\n",
      "\n",
      "--- Simulation run 50/100 ---\n",
      "\n",
      "--- Simulation run 51/100 ---\n",
      "\n",
      "--- Simulation run 52/100 ---\n",
      "\n",
      "--- Simulation run 53/100 ---\n",
      "\n",
      "--- Simulation run 54/100 ---\n",
      "\n",
      "--- Simulation run 55/100 ---\n",
      "\n",
      "--- Simulation run 56/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 57/100 ---\n",
      "\n",
      "--- Simulation run 58/100 ---\n",
      "\n",
      "--- Simulation run 59/100 ---\n",
      "\n",
      "--- Simulation run 60/100 ---\n",
      "\n",
      "--- Simulation run 61/100 ---\n",
      "\n",
      "--- Simulation run 62/100 ---\n",
      "\n",
      "--- Simulation run 63/100 ---\n",
      "\n",
      "--- Simulation run 64/100 ---\n",
      "\n",
      "--- Simulation run 65/100 ---\n",
      "\n",
      "--- Simulation run 66/100 ---\n",
      "\n",
      "--- Simulation run 67/100 ---\n",
      "\n",
      "--- Simulation run 68/100 ---\n",
      "\n",
      "--- Simulation run 69/100 ---\n",
      "\n",
      "--- Simulation run 70/100 ---\n",
      "\n",
      "--- Simulation run 71/100 ---\n",
      "\n",
      "--- Simulation run 72/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 73/100 ---\n",
      "\n",
      "--- Simulation run 74/100 ---\n",
      "\n",
      "--- Simulation run 75/100 ---\n",
      "\n",
      "--- Simulation run 76/100 ---\n",
      "\n",
      "--- Simulation run 77/100 ---\n",
      "\n",
      "--- Simulation run 78/100 ---\n",
      "\n",
      "--- Simulation run 79/100 ---\n",
      "\n",
      "--- Simulation run 80/100 ---\n",
      "\n",
      "--- Simulation run 81/100 ---\n",
      "\n",
      "--- Simulation run 82/100 ---\n",
      "\n",
      "--- Simulation run 83/100 ---\n",
      "\n",
      "--- Simulation run 84/100 ---\n",
      "\n",
      "--- Simulation run 85/100 ---\n",
      "\n",
      "--- Simulation run 86/100 ---\n",
      "\n",
      "--- Simulation run 87/100 ---\n",
      "\n",
      "--- Simulation run 88/100 ---\n",
      "\n",
      "--- Simulation run 89/100 ---\n",
      "\n",
      "--- Simulation run 90/100 ---\n",
      "\n",
      "--- Simulation run 91/100 ---\n",
      "\n",
      "--- Simulation run 92/100 ---\n",
      "\n",
      "--- Simulation run 93/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 94/100 ---\n",
      "\n",
      "--- Simulation run 95/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulation run 96/100 ---\n",
      "\n",
      "--- Simulation run 97/100 ---\n",
      "\n",
      "--- Simulation run 98/100 ---\n",
      "\n",
      "--- Simulation run 99/100 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zwei1/NNSFM/good_to_go/New_Sim_Dog_Cobbs/sfm_mle.py:26: RuntimeWarning: divide by zero encountered in log\n",
      "  logDen = np.log(Den)\n",
      "/home/zwei1/.conda/envs/d2l/lib/python3.9/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import importlib\n",
    "import nnwosd as wosd\n",
    "importlib.reload(wosd)\n",
    "from sfm_mle import estimate\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Number of Monte Carlo iterations\n",
    "n_iter = 100\n",
    "n_samples = 200\n",
    "\n",
    "# True parameters\n",
    "b_true = 2\n",
    "w_true = torch.tensor([.2])\n",
    "noise_std_v = 0.9\n",
    "noise_std_u = 0.2\n",
    "\n",
    "# Activations\n",
    "activations = {\n",
    "    \"ReLU\": nn.ReLU(),\n",
    "    \"ELU\": nn.ELU(),\n",
    "    \"FlippedReLU\": wosd.FlippedLeakRELU(alpha=0.8),\n",
    "    \"FlippedELU\": wosd.FlippedELU(alpha=0.8)\n",
    "}\n",
    "clamp_activations = [\"FlippedReLU\", \"FlippedELU\"]\n",
    "\n",
    "# Store results\n",
    "RMSE_nn_all   = {k: [] for k in activations.keys()}\n",
    "BIAS_nn_all   = {k: [] for k in activations.keys()}\n",
    "bias_v_nn_all = {k: [] for k in activations.keys()}\n",
    "bias_u_nn_all = {k: [] for k in activations.keys()}\n",
    "Bias_TE_nn_all= {k: [] for k in activations.keys()}\n",
    "\n",
    "\n",
    "# To store simulated datasets for each iteration\n",
    "simulated_datasets = []\n",
    "\n",
    "# Add SFM placeholders\n",
    "RMSE_nn_all['sfm']   = []\n",
    "BIAS_nn_all['sfm']   = []\n",
    "bias_v_nn_all['sfm'] = []\n",
    "bias_u_nn_all['sfm'] = []\n",
    "Bias_TE_nn_all['sfm']= []\n",
    "\n",
    "# Monte Carlo loop\n",
    "for run in range(n_iter):\n",
    "    print(f\"\\n--- Simulation run {run+1}/{n_iter} ---\")\n",
    "\n",
    "    # Generate data\n",
    "    noise_v = torch.from_numpy(np.random.normal(0, noise_std_v, size=(n_samples, 1)).astype(np.float32))\n",
    "    noise_u = torch.from_numpy(np.abs(np.random.normal(0, noise_std_u, size=(n_samples, 1)).astype(np.float32)))\n",
    "    # X = torch.from_numpy((np.random.uniform(0.01, 3, size=(n_samples, 1)).astype(np.float32)))\n",
    "    log_X = torch.from_numpy((np.random.uniform(-3, 3, size=(n_samples, 1)).astype(np.float32)))\n",
    "    X = torch.exp(log_X)\n",
    "    log_y = w_true * log_X + np.log(b_true) + (noise_v - noise_u)\n",
    "    \n",
    "    # Create a DataFrame with X, y, and noise terms\n",
    "    sim_df = pd.DataFrame({\n",
    "        \"log_X\": log_X.numpy().flatten(),\n",
    "        \"log_y\": log_y.numpy().flatten()\n",
    "    })\n",
    "    \n",
    "    simulated_datasets.append(sim_df)\n",
    "    \n",
    "    # Fit SFM (MLE)\n",
    "    y = log_y.numpy().flatten()\n",
    "    x1 = log_X.numpy().flatten()\n",
    "    coefs, sterr, logMLE = estimate(y, x1, b_true, w_true, noise_std_u, noise_std_v)\n",
    "\n",
    "    y_tf = ((X**w_true)*b_true).numpy()\n",
    "    # y_sfm_mean = ((X**coefs[1])*np.exp(coefs[0]))\n",
    "    #calculate the fitted y\n",
    "    # e_sfm = log_y - (coefs[0] + coefs[1] * log_X)\n",
    "    # e_sfm_np = e_sfm.detach().numpy()   # detach from graph, convert to NumPy\n",
    "    # E_sfm_correction = np.mean(np.exp(e_sfm_np))\n",
    "    E_sfm_correction = np.exp((coefs[2]+coefs[3])/2)\n",
    "    \n",
    "    y_sfm_mean = ((X.numpy() ** coefs[1]) * np.exp(coefs[0])) * E_sfm_correction\n",
    "    \n",
    "    RMSE_sfm = np.mean(((y_sfm_mean - y_tf) / y_tf)**2)\n",
    "    BIAS_sfm = np.mean(np.abs((y_sfm_mean - y_tf) / y_tf))\n",
    "    sigma_v_sfm = np.sqrt(coefs[3])\n",
    "    sigma_u_sfm = np.sqrt(coefs[2])\n",
    "    bias_v_sfm = np.abs(sigma_v_sfm - noise_std_v)\n",
    "    bias_u_sfm = np.abs(sigma_u_sfm - noise_std_u)\n",
    "\n",
    "    vectorized_TE_fun = np.vectorize(wosd.TE_fun)\n",
    "    TE_true = vectorized_TE_fun(\n",
    "        residuals=((np.log(y_tf)-(w_true * log_X + np.log(b_true)).numpy())),\n",
    "        sig_v=noise_std_v, sig_u=noise_std_u\n",
    "    )\n",
    "    TE_sfm = vectorized_TE_fun(\n",
    "        residuals=(np.log(y_sfm_mean) - log_y.numpy()),\n",
    "        sig_v=sigma_v_sfm, sig_u=sigma_u_sfm\n",
    "    )\n",
    "    Bias_TE_sfm = np.mean(np.abs(TE_sfm - TE_true))\n",
    "\n",
    "    # Store SFM results\n",
    "    RMSE_nn_all['sfm'].append(float(RMSE_sfm))\n",
    "    BIAS_nn_all['sfm'].append(float(BIAS_sfm))\n",
    "    bias_v_nn_all['sfm'].append(float(bias_v_sfm))\n",
    "    bias_u_nn_all['sfm'].append(float(bias_u_sfm))\n",
    "    Bias_TE_nn_all['sfm'].append(float(Bias_TE_sfm))\n",
    "\n",
    "    # Standardize data for NN\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    X_standardized = torch.tensor(scaler_X.fit_transform(log_X), dtype=torch.float32)\n",
    "    y_standardized = torch.tensor(scaler_y.fit_transform(log_y), dtype=torch.float32)\n",
    "\n",
    "    # Train NN models\n",
    "    for name, activation_fun in activations.items():\n",
    "        model = wosd.MLP(1, [32, 8], 1, activation_func=activation_fun)\n",
    "        nll_loss = wosd.GaussianNLLLoss(sigma_v=noise_std_v, sigma_u=noise_std_u)\n",
    "        optimizer = optim.Adam(list(model.parameters()) + [nll_loss.log_std_v, nll_loss.log_std_u], lr=0.01)\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        best_state = None\n",
    "        for epoch in range(1000):\n",
    "            model.train()\n",
    "            y_pred = model(X_standardized)\n",
    "            loss = nll_loss(y_pred, y_standardized)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if name in clamp_activations:\n",
    "                with torch.no_grad():\n",
    "                    for layer in model.layers:\n",
    "                        layer.weight.data.clamp_(min=0)\n",
    "                    model.output.weight.clamp_(min=0)\n",
    "\n",
    "            if loss.item() < best_loss:\n",
    "                best_loss = loss.item()\n",
    "                best_state = model.state_dict()\n",
    "\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        sigma_v_nn = torch.exp(nll_loss.log_std_v).item() * scaler_y.scale_\n",
    "        sigma_u_nn = torch.exp(nll_loss.log_std_u).item() * scaler_y.scale_\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred_std = model(X_standardized)\n",
    "            y_pred_std = y_pred_std + np.sqrt(2/np.pi) * sigma_u_nn\n",
    "            y_pred_original = scaler_y.inverse_transform(y_pred_std.numpy())\n",
    "            #calculate the fitted value\n",
    "            # y_original = scaler_y.inverse_transform(y_standardized.numpy())\n",
    "            # residuals_nn= y_original - y_pred_original\n",
    "            # E_nn_correction = residuals_nn.mean()\n",
    "            E_nn_correction = np.exp((sigma_v_nn**2+sigma_u_nn**2)/2)\n",
    "            y_pred_original = np.exp(y_pred_original)*E_nn_correction\n",
    "\n",
    "        rmse = np.sqrt(np.mean(((y_pred_original - y_tf) / y_tf)**2))\n",
    "        bias = np.mean(np.abs(y_pred_original - y_tf) / y_tf)\n",
    "        bias_v = np.abs(sigma_v_nn - noise_std_v)\n",
    "        bias_u = np.abs(sigma_u_nn - noise_std_u)\n",
    "\n",
    "        TE_nn = vectorized_TE_fun(\n",
    "            residuals=(y_pred_original - log_y.numpy()),\n",
    "            sig_v=sigma_v_nn, sig_u=sigma_u_nn\n",
    "        )\n",
    "        te_bias = np.mean(np.abs(TE_nn - TE_true))\n",
    "\n",
    "        \n",
    "        # Store results\n",
    "        RMSE_nn_all[name].append(float(rmse))\n",
    "        BIAS_nn_all[name].append(float(bias))\n",
    "        bias_v_nn_all[name].append(float(bias_v))\n",
    "        bias_u_nn_all[name].append(float(bias_u))\n",
    "        Bias_TE_nn_all[name].append(float(te_bias))\n",
    "    \n",
    "    \n",
    "# Summary statistics\n",
    "def summarize_results(metric_dict):\n",
    "    return {k: (np.mean(v), np.std(v)) for k, v in metric_dict.items()}\n",
    "\n",
    "print(\"\\n=== Mean (std) RMSE over 100 runs ===\")\n",
    "print(summarize_results(RMSE_nn_all))\n",
    "print(\"\\n=== Mean (std) BIAS over 100 runs ===\")\n",
    "print(summarize_results(BIAS_nn_all))\n",
    "print(\"\\n=== Mean (std) bias_v over 100 runs ===\")\n",
    "print(summarize_results(bias_v_nn_all))\n",
    "print(\"\\n=== Mean (std) bias_u over 100 runs ===\")\n",
    "print(summarize_results(bias_u_nn_all))\n",
    "print(\"\\n=== Mean (std) TE bias over 100 runs ===\")\n",
    "print(summarize_results(Bias_TE_nn_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af365231-9512-4fd1-a2a2-d18eaabc8d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mean (std) RMSE over 100 runs ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RMSE_nn_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: (np\u001b[38;5;241m.\u001b[39mmean(v), np\u001b[38;5;241m.\u001b[39mstd(v)) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m metric_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Mean (std) RMSE over 100 runs ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(summarize_results(\u001b[43mRMSE_nn_all\u001b[49m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== Mean (std) BIAS over 100 runs ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(summarize_results(BIAS_nn_all))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RMSE_nn_all' is not defined"
     ]
    }
   ],
   "source": [
    "def summarize_results(metric_dict):\n",
    "    return {k: (np.mean(v), np.std(v)) for k, v in metric_dict.items()}\n",
    "\n",
    "print(\"\\n=== Mean (std) RMSE over 100 runs ===\")\n",
    "print(summarize_results(RMSE_nn_all))\n",
    "print(\"\\n=== Mean (std) BIAS over 100 runs ===\")\n",
    "print(summarize_results(BIAS_nn_all))\n",
    "print(\"\\n=== Mean (std) bias_v over 100 runs ===\")\n",
    "print(summarize_results(bias_v_nn_all))\n",
    "print(\"\\n=== Mean (std) bias_u over 100 runs ===\")\n",
    "print(summarize_results(bias_u_nn_all))\n",
    "print(\"\\n=== Mean (std) TE bias over 100 runs ===\")\n",
    "print(summarize_results(Bias_TE_nn_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d06a19-0263-4774-a14e-524020da580a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3ed6e-a04b-40f7-9126-c9b6aa403c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7350e5b-2a0e-416f-b2ff-37e091c0bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"simulated_data\", exist_ok=True)\n",
    "\n",
    "for i, sim_df in enumerate(simulated_datasets, start=1):\n",
    "    file_path = f\"simulated_data/sim_data_iter_{i}.csv\"\n",
    "    sim_df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(simulated_datasets)} simulated datasets in 'simulated_data/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd0510-9fd2-4b59-ab13-cd6d564d84ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# os.makedirs(\"simulated_data\", exist_ok=True)\n",
    "\n",
    "# # Save the simulated_datasets list\n",
    "# with open(\"simulated_data/simulated_datasets.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(simulated_datasets, f)\n",
    "\n",
    "# # Save the metrics as a dict\n",
    "# metrics_dict = {\n",
    "#     \"RMSE_nn_all\": RMSE_nn_all,\n",
    "#     \"BIAS_nn_all\": BIAS_nn_all,\n",
    "#     \"bias_v_nn_all\": bias_v_nn_all,\n",
    "#     \"bias_u_nn_all\": bias_u_nn_all,\n",
    "#     \"Bias_TE_nn_all\": Bias_TE_nn_all\n",
    "# }\n",
    "# with open(\"simulated_data/metrics.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(metrics_dict, f)\n",
    "\n",
    "# print(\"Saved simulated datasets and metrics as Pickle files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4c3889-3ad8-4b16-aba2-562ff076b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Summary statistics\n",
    "def summarize_results(metric_dict):\n",
    "    return {k: (np.mean(v), np.std(v)) for k, v in metric_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3cda608-eee8-4e21-ae9c-633acad2a1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['RMSE_nn_all', 'BIAS_nn_all', 'bias_v_nn_all', 'bias_u_nn_all', 'Bias_TE_nn_all'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load simulated datasets\n",
    "with open(\"simulated_data/simulated_datasets.pkl\", \"rb\") as f:\n",
    "    simulated_datasets = pickle.load(f)\n",
    "\n",
    "# Load metrics\n",
    "with open(\"simulated_data/metrics.pkl\", \"rb\") as f:\n",
    "    metrics = pickle.load(f)\n",
    "\n",
    "print(metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523f63af-ca62-4f41-9f29-23564697273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mean (std) RMSE over 100 runs ===\n",
      "{'ReLU': (0.6390168641938269, 0.1480993092579175), 'ELU': (0.5977172084726952, 0.14090949680232984), 'FlippedReLU': (0.5187590563422317, 0.13158599630693982), 'FlippedELU': (0.5236267867599146, 0.1312897730606343), 'sfm': (0.27425441712141035, 0.03524368139043235)}\n",
      "\n",
      "=== Mean (std) BIAS over 100 runs ===\n",
      "{'ReLU': (0.5082098294873404, 0.12250912906656748), 'ELU': (0.5102376253767004, 0.12505464429725813), 'FlippedReLU': (0.507530885288058, 0.1310673562661376), 'FlippedELU': (0.50844922941556, 0.1310495505635086), 'sfm': (0.5158164793252945, 0.029842520204196636)}\n",
      "\n",
      "=== Mean (std) bias_v over 100 runs ===\n",
      "{'ReLU': (0.05957000657729781, 0.03955621440945941), 'ELU': (0.04686149149640669, 0.035348941855314016), 'FlippedReLU': (0.039995576792693034, 0.028350121312007186), 'FlippedELU': (0.039975268061382165, 0.028891607042543118), 'sfm': (0.00883245475870044, 0.0177473529373095)}\n",
      "\n",
      "=== Mean (std) bias_u over 100 runs ===\n",
      "{'ReLU': (0.013237697500287663, 0.00879024812988944), 'ELU': (0.010413611026485272, 0.007855290035361362), 'FlippedReLU': (0.008887904717965358, 0.006300022739920592), 'FlippedELU': (0.008883391940763556, 0.006420349949592475), 'sfm': (0.022483813411935793, 0.04113794061193396)}\n",
      "\n",
      "=== Mean (std) TE bias over 100 runs ===\n",
      "{'ReLU': (0.03941458348199973, 0.005515155410600693), 'ELU': (0.03714064430662737, 0.005201874145167121), 'FlippedReLU': (0.034468442630119535, 0.005178652592324566), 'FlippedELU': (0.034593993313179826, 0.0051781057654430905), 'sfm': (0.02480596635039277, 0.02449988892285644)}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Mean (std) RMSE over 100 runs ===\")\n",
    "print(summarize_results(metrics['RMSE_nn_all']))\n",
    "print(\"\\n=== Mean (std) BIAS over 100 runs ===\")\n",
    "print(summarize_results(metrics['BIAS_nn_all']))\n",
    "print(\"\\n=== Mean (std) bias_v over 100 runs ===\")\n",
    "print(summarize_results(metrics['bias_v_nn_all']))\n",
    "print(\"\\n=== Mean (std) bias_u over 100 runs ===\")\n",
    "print(summarize_results(metrics['bias_u_nn_all']))\n",
    "print(\"\\n=== Mean (std) TE bias over 100 runs ===\")\n",
    "print(summarize_results(metrics['Bias_TE_nn_all']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01cb0ca-ac6a-4069-bbe3-2222c92acff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
