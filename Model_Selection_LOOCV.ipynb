{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a6f83d4-97e5-4652-9164-151b17909a98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clear all variables\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ca57e64-55c1-419e-be32-eae6d5a23eca",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from torch.distributions import Normal\n",
    "import nnwosd as wosd\n",
    "import importlib\n",
    "importlib.reload(wosd)\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import torch.nn.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c9b2cc6-0567-4329-a6a8-04cd1fd34f85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('rice92_data.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24ffb3b-9d02-4fa6-a3a5-08475b2b3980",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEARDUM', 'FMERCODE', 'PROD', 'AREA', 'LABOR', 'NPK', 'OTHER', 'PRICE',\n",
       "       'AREAP', 'LABORP', 'NPKP', 'OTHERP', 'AGE', 'EDYRS', 'HHSIZE', 'NADULT',\n",
       "       'BANRAT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dict.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56ba7b68-ae90-4887-9fb2-64dc91066578",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loaded_dict\n",
    "\n",
    "x1= torch.tensor(np.log(np.array(loaded_dict['AREA']))).reshape(-1,1)\n",
    "x2= torch.tensor(np.log(np.array(loaded_dict['LABOR']))).reshape(-1,1)\n",
    "x3= torch.tensor(np.log(np.array(loaded_dict['NPK']))).reshape(-1,1)\n",
    "x_tensor = torch.cat((x1,x2,x3), dim=1)\n",
    "y = torch.tensor(np.log(np.array(loaded_dict['PROD']))).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a189a3c1-afcc-4a65-ad00-b62f7f38651a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Standardize input and output data\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "# Fit scalers on the data and transform\n",
    "X_standardized = torch.tensor(scaler_X.fit_transform(x_tensor), dtype=torch.float32)\n",
    "y_standardized = torch.tensor(scaler_y.fit_transform(y), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e6af87-83c8-4702-b42b-b2018800978d",
   "metadata": {},
   "source": [
    "# LOOCV for model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaf055f8-feec-4e95-a4cb-8bc3fdd24d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Starting 2_layers architecture: [32, 16]\n",
      "Architecture 2_layers, [32, 16]: LOOCV Loss = 0.2113\n",
      "\n",
      ">>> Starting 2_layers architecture: [32, 8]\n",
      "Architecture 2_layers, [32, 8]: LOOCV Loss = 0.5879\n",
      "\n",
      ">>> Starting 2_layers architecture: [16, 8]\n",
      "Architecture 2_layers, [16, 8]: LOOCV Loss = 0.3158\n",
      "\n",
      ">>> Starting 2_layers architecture: [8, 4]\n",
      "Architecture 2_layers, [8, 4]: LOOCV Loss = 0.3527\n",
      "\n",
      ">>> Starting 2_layers architecture: [4, 4]\n",
      "Architecture 2_layers, [4, 4]: LOOCV Loss = 0.6421\n",
      "\n",
      ">>> Starting 3_layers architecture: [16, 8, 4]\n",
      "Architecture 3_layers, [16, 8, 4]: LOOCV Loss = nan\n",
      "\n",
      ">>> Starting 3_layers architecture: [8, 4, 2]\n",
      "Architecture 3_layers, [8, 4, 2]: LOOCV Loss = nan\n",
      "\n",
      ">>> Starting 3_layers architecture: [4, 2, 2]\n",
      "Architecture 3_layers, [4, 2, 2]: LOOCV Loss = 0.6833\n",
      "\n",
      "Best architectures by LOOCV:\n",
      "('2_layers', (32, 16)) -> 0.21126475283872634\n",
      "('2_layers', (16, 8)) -> 0.31583843751947577\n",
      "('2_layers', (8, 4)) -> 0.35271253015515525\n",
      "('2_layers', (32, 8)) -> 0.5879406441546421\n",
      "('2_layers', (4, 4)) -> 0.6421344573940345\n",
      "('3_layers', (16, 8, 4)) -> nan\n",
      "('3_layers', (8, 4, 2)) -> nan\n",
      "('3_layers', (4, 2, 2)) -> 0.6833269932752702\n"
     ]
    }
   ],
   "source": [
    "# ------------------ MLP with Dropout ------------------\n",
    "class MLPWithDropout(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, activation_func, dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_size = input_size\n",
    "        self.linear_layers = nn.ModuleList()\n",
    "        for h in hidden_sizes:\n",
    "            linear = nn.Linear(in_size, h)\n",
    "            self.linear_layers.append(linear)\n",
    "            layers.append(linear)\n",
    "            layers.append(activation_func)\n",
    "            layers.append(nn.Dropout(dropout))  # Dropout after activation\n",
    "            in_size = h\n",
    "        self.output = nn.Linear(in_size, output_size)\n",
    "        layers.append(self.output)\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ------------------ Train function ------------------\n",
    "def train_model(X_train, y_train, X_val, y_val, hidden_sizes, sigma_v, sigma_u, \n",
    "                epochs=300, lr=0.005, dropout=0.1, weight_decay=1e-4):\n",
    "    \n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 1\n",
    "\n",
    "    activation_fun = wosd.FlippedELU(alpha=.8)\n",
    "    model = MLPWithDropout(input_size, hidden_sizes, output_size, activation_func=activation_fun, dropout=dropout)\n",
    "\n",
    "    nll_loss = wosd.GaussianNLLLoss(sigma_v=sigma_v, sigma_u=sigma_u)\n",
    "    optimizer = optim.Adam(list(model.parameters()) + [nll_loss.log_std_v, nll_loss.log_std_u],\n",
    "                           lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_state = model.state_dict()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        y_pred = model(X_train)\n",
    "        loss = nll_loss(y_pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clamp weights for monotonicity\n",
    "        with torch.no_grad():\n",
    "            for layer in model.linear_layers:\n",
    "                layer.weight.data.clamp_(min=0)\n",
    "            model.output.weight.data.clamp_(min=0)\n",
    "\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "    # Validation\n",
    "    model.load_state_dict(best_state)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_pred = model(X_val)\n",
    "        val_loss = nll_loss(y_val_pred, y_val).item()\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "# ------------------ LOOCV loop ------------------\n",
    "architectures = {\n",
    "    \"2_layers\": [[32,16], [32,8], [16,8], [8,4], [4,4]],\n",
    "    \"3_layers\": [[16,8,4], [8,4,2], [4,2,2]]\n",
    "}\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "results = {}\n",
    "\n",
    "for arch_name, configs in architectures.items():\n",
    "    for hidden_sizes in configs:\n",
    "        print(f\"\\n>>> Starting {arch_name} architecture: {hidden_sizes}\")\n",
    "        val_losses = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(loo.split(X_standardized), start=1):\n",
    "            print(f\"   Fold {fold}/{len(X_standardized)} ...\", end=\"\\r\")\n",
    "            X_train, X_val = X_standardized[train_idx], X_standardized[val_idx]\n",
    "            y_train, y_val = y_standardized[train_idx], y_standardized[val_idx]\n",
    "\n",
    "            loss_val = train_model(\n",
    "                X_train, y_train, X_val, y_val,\n",
    "                hidden_sizes,\n",
    "                sigma_v=sigma_v_sfm, sigma_u=sigma_u_sfm,\n",
    "                epochs=300, lr=0.005,\n",
    "                dropout=0.1, weight_decay=1e-4\n",
    "            )\n",
    "            val_losses.append(loss_val)\n",
    "\n",
    "        avg_loss = np.mean(val_losses)\n",
    "        results[(arch_name, tuple(hidden_sizes))] = avg_loss\n",
    "        print(f\"Architecture {arch_name}, {hidden_sizes}: LOOCV Loss = {avg_loss:.4f}\")\n",
    "\n",
    "# ------------------ Print sorted results ------------------\n",
    "results_sorted = sorted(results.items(), key=lambda x: x[1])\n",
    "print(\"\\nBest architectures by LOOCV:\")\n",
    "for arch, loss_val in results_sorted:\n",
    "    print(arch, \"->\", loss_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc127677-487a-4727-9b3f-fcbf671185c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
