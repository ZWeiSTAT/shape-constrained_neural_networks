{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f3dc942-cad4-49a5-abfb-8c2cf4cc8fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘foreach’ was built under R version 4.2.3”\n",
      "Loading required package: iterators\n",
      "\n",
      "Warning message:\n",
      "“package ‘iterators’ was built under R version 4.2.3”\n",
      "Loading required package: parallel\n",
      "\n",
      "Loading required package: micEcon\n",
      "\n",
      "\n",
      "If you have questions, suggestions, or comments regarding one of the 'micEcon' packages, please use a forum or 'tracker' at micEcon's R-Forge site:\n",
      "https://r-forge.r-project.org/projects/micecon/\n",
      "\n",
      "Loading required package: lmtest\n",
      "\n",
      "Loading required package: zoo\n",
      "\n",
      "\n",
      "Attaching package: ‘zoo’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "\n",
      "\n",
      "Please cite the 'frontier' package as:\n",
      "Tim Coelli and Arne Henningsen (2013). frontier: Stochastic Frontier Analysis. R package version 1.1. http://CRAN.R-Project.org/package=frontier.\n",
      "\n",
      "If you have questions, suggestions, or comments regarding the 'frontier' package, please use a forum or 'tracker' at frontier's R-Forge site:\n",
      "https://r-forge.r-project.org/projects/frontier/\n",
      "\n",
      "Loading required package: stats4\n",
      "\n",
      "\n",
      "Attaching package: ‘sn’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    sd\n",
      "\n",
      "\n",
      "Loading required package: mgcv\n",
      "\n",
      "Loading required package: nlme\n",
      "\n",
      "This is mgcv 1.8-41. For overview type 'help(\"mgcv-package\")'.\n",
      "\n",
      "Loading required package: np\n",
      "\n",
      "Warning message:\n",
      "“package ‘np’ was built under R version 4.2.3”\n",
      "Nonparametric Kernel Methods for Mixed Datatypes (version 0.60-17)\n",
      "[vignette(\"np_faq\",package=\"np\") provides answers to frequently asked questions]\n",
      "[vignette(\"np\",package=\"np\") an overview]\n",
      "[vignette(\"entropy_np\",package=\"np\") an overview of entropy-based methods]\n",
      "\n",
      "Loading required package: gamlss\n",
      "\n",
      "Loading required package: splines\n",
      "\n",
      "Loading required package: gamlss.data\n",
      "\n",
      "\n",
      "Attaching package: ‘gamlss.data’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:datasets’:\n",
      "\n",
      "    sleep\n",
      "\n",
      "\n",
      "Loading required package: gamlss.dist\n",
      "\n",
      " **********   GAMLSS Version 5.4-3  ********** \n",
      "\n",
      "For more on GAMLSS look at https://www.gamlss.com/\n",
      "\n",
      "Type gamlssNews() to see new features/changes/bug fixes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rm(list = ls())\n",
    "#setwd('/Users/zhengwei/Desktop/OneDrive - Texas A&M University-Corpus Christi/Research/Huiyan_Sang/DecisionTree/MyPackage/sim1_lin')\n",
    "#setwd(\"/Users/zhengwei/OneDrive - Texas A&M University-Corpus Christi/Research/Huiyan_Sang/DecisionTree/MyPackage/sim1_lin\")\n",
    "\n",
    "library(foreach)\n",
    "library(doMC)\n",
    "library(coda)\n",
    "library(MonBartSFM)\n",
    "library(frontier)\n",
    "library(truncnorm)\n",
    "library(sn)\n",
    "library(MASS)\n",
    "library(semsfa)\n",
    "source(\"otherfuns.R\")\n",
    "source(\"Bayes_SFM_NHN_Gibbs.R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfa84ef-70e6-43a7-9dc4-a041485f99a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>log_X</th><th scope=col>log_y</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td> 2.768552</td><td> 0.2527462</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>-2.856968</td><td>-0.6890037</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>-1.137870</td><td> 0.5694323</td></tr>\n",
       "\t<tr><th scope=row>4</th><td> 2.452089</td><td> 2.5354790</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>-1.278954</td><td> 1.4797850</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>-1.649340</td><td> 0.2519563</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & log\\_X & log\\_y\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 &  2.768552 &  0.2527462\\\\\n",
       "\t2 & -2.856968 & -0.6890037\\\\\n",
       "\t3 & -1.137870 &  0.5694323\\\\\n",
       "\t4 &  2.452089 &  2.5354790\\\\\n",
       "\t5 & -1.278954 &  1.4797850\\\\\n",
       "\t6 & -1.649340 &  0.2519563\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | log_X &lt;dbl&gt; | log_y &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 1 |  2.768552 |  0.2527462 |\n",
       "| 2 | -2.856968 | -0.6890037 |\n",
       "| 3 | -1.137870 |  0.5694323 |\n",
       "| 4 |  2.452089 |  2.5354790 |\n",
       "| 5 | -1.278954 |  1.4797850 |\n",
       "| 6 | -1.649340 |  0.2519563 |\n",
       "\n"
      ],
      "text/plain": [
       "  log_X     log_y     \n",
       "1  2.768552  0.2527462\n",
       "2 -2.856968 -0.6890037\n",
       "3 -1.137870  0.5694323\n",
       "4  2.452089  2.5354790\n",
       "5 -1.278954  1.4797850\n",
       "6 -1.649340  0.2519563"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set path to your folder\n",
    "path <- \"simulated_data\"\n",
    "\n",
    "# List all CSV files in that folder\n",
    "files <- list.files(path, pattern = \"\\\\.csv$\", full.names = TRUE)\n",
    "\n",
    "# Read each CSV into a list of data.frames\n",
    "simulated_datasets_R <- lapply(files, read.csv)\n",
    "\n",
    "# Access the first dataset\n",
    "head(simulated_datasets_R[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6104df-bd6e-4587-9a42-6a1902d2d3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=  1 \n",
      "Cumulative average: iter= 1000 beta0= 0.8437 beta= 0.2106 sigmav= 0.8599 sigmau= 0.3147 \n",
      "Cumulative average: iter= 2000 beta0= 0.8358 beta= 0.2099 sigmav= 0.8611 sigmau= 0.305 \n",
      "Cumulative average: iter= 3000 beta0= 0.8181 beta= 0.21 sigmav= 0.8653 sigmau= 0.2842 \n",
      "Cumulative average: iter= 4000 beta0= 0.8144 beta= 0.2106 sigmav= 0.8665 sigmau= 0.279 \n",
      "Cumulative average: iter= 5000 beta0= 0.8194 beta= 0.2106 sigmav= 0.8653 sigmau= 0.2862 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: Rcpp\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.781881, -0.183035\n",
      "first row: 2.768552, 2.768552\n",
      "second row: -2.856968, -2.856968\n",
      "last row: 1.221842, 1.221842\n",
      "no test observations\n",
      "tau: 0.151553\n",
      "nu: 3.000000\n",
      "lambda: 0.067982\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.934925 ... 2.914727\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.781881, -0.183035\n",
      "first row: 2.768552, 2.768552\n",
      "second row: -2.856968, -2.856968\n",
      "last row: 1.221842, 1.221842\n",
      "no test observations\n",
      "tau: 0.151553\n",
      "nu: 3.000000\n",
      "lambda: 0.067982\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.934925 ... 2.914727\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  2 \n",
      "Cumulative average: iter= 1000 beta0= 0.6969 beta= 0.1264 sigmav= 0.7807 sigmau= 0.2628 \n",
      "Cumulative average: iter= 2000 beta0= 0.6916 beta= 0.1257 sigmav= 0.7816 sigmau= 0.2555 \n",
      "Cumulative average: iter= 3000 beta0= 0.6897 beta= 0.1252 sigmav= 0.7823 sigmau= 0.2536 \n",
      "Cumulative average: iter= 4000 beta0= 0.698 beta= 0.1248 sigmav= 0.7807 sigmau= 0.2644 \n",
      "Cumulative average: iter= 5000 beta0= 0.6938 beta= 0.1249 sigmav= 0.7812 sigmau= 0.26 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.426301, -0.368552\n",
      "first row: -0.016410, -0.016410\n",
      "second row: 1.469114, 1.469114\n",
      "last row: -2.066396, -2.066396\n",
      "no test observations\n",
      "tau: 0.169812\n",
      "nu: 3.000000\n",
      "lambda: 0.071770\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.920105 ... 2.939239\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.426301, -0.368552\n",
      "first row: -0.016410, -0.016410\n",
      "second row: 1.469114, 1.469114\n",
      "last row: -2.066396, -2.066396\n",
      "no test observations\n",
      "tau: 0.169812\n",
      "nu: 3.000000\n",
      "lambda: 0.071770\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.920105 ... 2.939239\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  3 \n",
      "Cumulative average: iter= 1000 beta0= 0.8251 beta= 0.1379 sigmav= 0.853 sigmau= 0.2821 \n",
      "Cumulative average: iter= 2000 beta0= 0.8137 beta= 0.1378 sigmav= 0.8555 sigmau= 0.2673 \n",
      "Cumulative average: iter= 3000 beta0= 0.8421 beta= 0.1374 sigmav= 0.848 sigmau= 0.3019 \n",
      "Cumulative average: iter= 4000 beta0= 0.8346 beta= 0.1373 sigmav= 0.8497 sigmau= 0.292 \n",
      "Cumulative average: iter= 5000 beta0= 0.8284 beta= 0.1365 sigmav= 0.8509 sigmau= 0.2849 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.403193, -1.448909\n",
      "first row: 0.804689, 0.804689\n",
      "second row: -2.994479, -2.994479\n",
      "last row: -2.581011, -2.581011\n",
      "no test observations\n",
      "tau: 0.139126\n",
      "nu: 3.000000\n",
      "lambda: 0.053512\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.935372 ... 2.916254\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.403193, -1.448909\n",
      "first row: 0.804689, 0.804689\n",
      "second row: -2.994479, -2.994479\n",
      "last row: -2.581011, -2.581011\n",
      "no test observations\n",
      "tau: 0.139126\n",
      "nu: 3.000000\n",
      "lambda: 0.053512\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.935372 ... 2.916254\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  4 \n",
      "Cumulative average: iter= 1000 beta0= 0.7945 beta= 0.1895 sigmav= 0.9465 sigmau= 0.2841 \n",
      "Cumulative average: iter= 2000 beta0= 0.7994 beta= 0.1907 sigmav= 0.9486 sigmau= 0.2858 \n",
      "Cumulative average: iter= 3000 beta0= 0.7904 beta= 0.1913 sigmav= 0.9489 sigmau= 0.2745 \n",
      "Cumulative average: iter= 4000 beta0= 0.7848 beta= 0.1911 sigmav= 0.9503 sigmau= 0.2669 \n",
      "Cumulative average: iter= 5000 beta0= 0.7882 beta= 0.191 sigmav= 0.9494 sigmau= 0.2712 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.856808, -0.969793\n",
      "first row: 2.284852, 2.284852\n",
      "second row: -2.000353, -2.000353\n",
      "last row: 0.533287, 0.533287\n",
      "no test observations\n",
      "tau: 0.158406\n",
      "nu: 3.000000\n",
      "lambda: 0.106566\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.916768 ... 2.913810\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.856808, -0.969793\n",
      "first row: 2.284852, 2.284852\n",
      "second row: -2.000353, -2.000353\n",
      "last row: 0.533287, 0.533287\n",
      "no test observations\n",
      "tau: 0.158406\n",
      "nu: 3.000000\n",
      "lambda: 0.106566\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.916768 ... 2.913810\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  5 \n",
      "Cumulative average: iter= 1000 beta0= 0.7211 beta= 0.2908 sigmav= 0.8584 sigmau= 0.3173 \n",
      "Cumulative average: iter= 2000 beta0= 0.6862 beta= 0.2902 sigmav= 0.8644 sigmau= 0.2746 \n",
      "Cumulative average: iter= 3000 beta0= 0.6876 beta= 0.2903 sigmav= 0.8631 sigmau= 0.2765 \n",
      "Cumulative average: iter= 4000 beta0= 0.6838 beta= 0.2898 sigmav= 0.8645 sigmau= 0.2726 \n",
      "Cumulative average: iter= 5000 beta0= 0.6925 beta= 0.2895 sigmav= 0.8626 sigmau= 0.2834 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.050500, 1.732206\n",
      "first row: 2.820841, 2.820841\n",
      "second row: 1.113086, 1.113086\n",
      "last row: 1.427586, 1.427586\n",
      "no test observations\n",
      "tau: 0.141103\n",
      "nu: 3.000000\n",
      "lambda: 0.088212\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.919329 ... 2.920146\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 1.050500, 1.732206\n",
      "first row: 2.820841, 2.820841\n",
      "second row: 1.113086, 1.113086\n",
      "last row: 1.427586, 1.427586\n",
      "no test observations\n",
      "tau: 0.141103\n",
      "nu: 3.000000\n",
      "lambda: 0.088212\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.919329 ... 2.920146\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  6 \n",
      "Cumulative average: iter= 1000 beta0= 0.6688 beta= 0.2256 sigmav= 0.925 sigmau= 0.3235 \n",
      "Cumulative average: iter= 2000 beta0= 0.6396 beta= 0.2247 sigmav= 0.9318 sigmau= 0.2878 \n",
      "Cumulative average: iter= 3000 beta0= 0.6304 beta= 0.2244 sigmav= 0.9326 sigmau= 0.2752 \n",
      "Cumulative average: iter= 4000 beta0= 0.64 beta= 0.2247 sigmav= 0.9316 sigmau= 0.2878 \n",
      "Cumulative average: iter= 5000 beta0= 0.6322 beta= 0.2241 sigmav= 0.9321 sigmau= 0.2789 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.537583, -0.160084\n",
      "first row: 0.497729, 0.497729\n",
      "second row: 0.956135, 0.956135\n",
      "last row: -2.559285, -2.559285\n",
      "no test observations\n",
      "tau: 0.190411\n",
      "nu: 3.000000\n",
      "lambda: 0.103045\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.935967 ... 2.936994\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -0.537583, -0.160084\n",
      "first row: 0.497729, 0.497729\n",
      "second row: 0.956135, 0.956135\n",
      "last row: -2.559285, -2.559285\n",
      "no test observations\n",
      "tau: 0.190411\n",
      "nu: 3.000000\n",
      "lambda: 0.103045\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.935967 ... 2.936994\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  7 \n",
      "Cumulative average: iter= 1000 beta0= 0.8419 beta= 0.2592 sigmav= 0.8352 sigmau= 0.3699 \n",
      "Cumulative average: iter= 2000 beta0= 0.8344 beta= 0.2584 sigmav= 0.8381 sigmau= 0.3597 \n",
      "Cumulative average: iter= 3000 beta0= 0.8259 beta= 0.259 sigmav= 0.8409 sigmau= 0.3495 \n",
      "Cumulative average: iter= 4000 beta0= 0.8131 beta= 0.2591 sigmav= 0.8438 sigmau= 0.3346 \n",
      "Cumulative average: iter= 5000 beta0= 0.8082 beta= 0.259 sigmav= 0.8459 sigmau= 0.3281 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.460286, -0.033755\n",
      "first row: 2.812615, 2.812615\n",
      "second row: -0.737347, -0.737347\n",
      "last row: -2.008877, -2.008877\n",
      "no test observations\n",
      "tau: 0.162237\n",
      "nu: 3.000000\n",
      "lambda: 0.032114\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.930749 ... 2.918369\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: -1.460286, -0.033755\n",
      "first row: 2.812615, 2.812615\n",
      "second row: -0.737347, -0.737347\n",
      "last row: -2.008877, -2.008877\n",
      "no test observations\n",
      "tau: 0.162237\n",
      "nu: 3.000000\n",
      "lambda: 0.032114\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.930749 ... 2.918369\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  8 \n",
      "Cumulative average: iter= 1000 beta0= 0.7769 beta= 0.1715 sigmav= 0.9525 sigmau= 0.2606 \n",
      "Cumulative average: iter= 2000 beta0= 0.7812 beta= 0.1699 sigmav= 0.9519 sigmau= 0.2633 \n",
      "Cumulative average: iter= 3000 beta0= 0.775 beta= 0.1701 sigmav= 0.9533 sigmau= 0.2541 \n",
      "Cumulative average: iter= 4000 beta0= 0.7794 beta= 0.1703 sigmav= 0.9528 sigmau= 0.2587 \n",
      "Cumulative average: iter= 5000 beta0= 0.7751 beta= 0.1702 sigmav= 0.9538 sigmau= 0.2527 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 3.673180, 1.287348\n",
      "first row: 2.432557, 2.432557\n",
      "second row: -1.844794, -1.844794\n",
      "last row: -0.268412, -0.268412\n",
      "no test observations\n",
      "tau: 0.171777\n",
      "nu: 3.000000\n",
      "lambda: 0.107254\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.892366 ... 2.938011\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 3.673180, 1.287348\n",
      "first row: 2.432557, 2.432557\n",
      "second row: -1.844794, -1.844794\n",
      "last row: -0.268412, -0.268412\n",
      "no test observations\n",
      "tau: 0.171777\n",
      "nu: 3.000000\n",
      "lambda: 0.107254\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.892366 ... 2.938011\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  9 \n",
      "Cumulative average: iter= 1000 beta0= 0.7979 beta= 0.212 sigmav= 0.8891 sigmau= 0.2892 \n",
      "Cumulative average: iter= 2000 beta0= 0.7894 beta= 0.211 sigmav= 0.8921 sigmau= 0.28 \n",
      "Cumulative average: iter= 3000 beta0= 0.7808 beta= 0.2109 sigmav= 0.8938 sigmau= 0.2684 \n",
      "Cumulative average: iter= 4000 beta0= 0.7839 beta= 0.2105 sigmav= 0.8925 sigmau= 0.2716 \n",
      "Cumulative average: iter= 5000 beta0= 0.7774 beta= 0.2104 sigmav= 0.8937 sigmau= 0.2635 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in semsfa(y ~ pbm(x, mono = \"up\"), sem.method = \"gam.mono\", dati):\n",
      "“the residuals of the FirstStep estimates are left skewed \n",
      " this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the residuals of the OLS estimates are right-skewed; this might indicate that there is no inefficiency or that the model is misspecified”\n",
      "Warning message in sfa(y1 ~ lnx1, data = simdt):\n",
      "“the parameter 'gamma' is close to the boundary of the parameter space [0,1]: this can cause convergence problems and can negatively affect the validity and reliability of statistical tests and might be caused by model misspecification”\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.911829, 1.185056\n",
      "first row: -1.912744, -1.912744\n",
      "second row: 1.048040, 1.048040\n",
      "last row: -1.057221, -1.057221\n",
      "no test observations\n",
      "tau: 0.155951\n",
      "nu: 3.000000\n",
      "lambda: 0.094047\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.919063 ... 2.938223\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.911829, 1.185056\n",
      "first row: -1.912744, -1.912744\n",
      "second row: 1.048040, 1.048040\n",
      "last row: -1.057221, -1.057221\n",
      "no test observations\n",
      "tau: 0.155951\n",
      "nu: 3.000000\n",
      "lambda: 0.094047\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.919063 ... 2.938223\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "i=  10 \n",
      "Cumulative average: iter= 1000 beta0= 0.7951 beta= 0.1809 sigmav= 0.8378 sigmau= 0.2567 \n",
      "Cumulative average: iter= 2000 beta0= 0.8218 beta= 0.1797 sigmav= 0.8329 sigmau= 0.2896 \n",
      "Cumulative average: iter= 3000 beta0= 0.8314 beta= 0.1795 sigmav= 0.83 sigmau= 0.3019 \n",
      "Cumulative average: iter= 4000 beta0= 0.8353 beta= 0.1796 sigmav= 0.8293 sigmau= 0.3067 \n",
      "Cumulative average: iter= 5000 beta0= 0.8361 beta= 0.1797 sigmav= 0.83 sigmau= 0.3074 \n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.550130, 0.682000\n",
      "first row: 1.504866, 1.504866\n",
      "second row: -1.170074, -1.170074\n",
      "last row: 1.289444, 1.289444\n",
      "no test observations\n",
      "tau: 0.141808\n",
      "nu: 3.000000\n",
      "lambda: 0.067271\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.918780 ... 2.928569\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n",
      "This is my mon-Bart code\n",
      "*****Into main of monotonic bart\n",
      "**********************\n",
      "n: 200\n",
      "p: 1\n",
      "first and last y: 0.550130, 0.682000\n",
      "first row: 1.504866, 1.504866\n",
      "second row: -1.170074, -1.170074\n",
      "last row: 1.289444, 1.289444\n",
      "no test observations\n",
      "tau: 0.141808\n",
      "nu: 3.000000\n",
      "lambda: 0.067271\n",
      "tree prior base: 0.250000\n",
      "tree prior power: 0.800000\n",
      "burn (nskip): 1000\n",
      "nd (ndpost): 4000\n",
      "m (ntree): 100\n",
      "nm (mu grid size): 50\n",
      "*****nkeeptrain,nkeeptest,nkeeptestme, nkeeptreedraws: 4000, 4000, 4000, 4000\n",
      "*****printevery: 100\n",
      "*****skiptr,skipte,skipteme,skiptreedraws: 1,1,1,1\n",
      "**********************\n",
      "dip.n: 0\n",
      "x1 cuts: -2.918780 ... 2.928569\n",
      "check counts\n",
      "trcnt,tecnt,temecnt,treedrawscnt: 4000,0,0, 4000\n"
     ]
    }
   ],
   "source": [
    "#set cores for parallel computing\n",
    "RNGkind(\"L'Ecuyer-CMRG\")\n",
    "cores<-strtoi(Sys.getenv('SLURM_CPUS_PER_TASK', unset=1))\n",
    "registerDoMC(cores)\n",
    "\n",
    "part=1\n",
    "\n",
    "res<-foreach(i=1:10) %dopar% {\n",
    "  cat(\"i= \",i,'\\n')\n",
    "\n",
    "finished <- FALSE\n",
    "while(!finished) {\n",
    "    tryCatch({\n",
    "\n",
    "  ##########################################\n",
    "  #    simulate data for linear case       #\n",
    "  ##########################################\n",
    "  ## simulate simple data with one x\n",
    "  beta0=log(2)\n",
    "  beta1=0.2\n",
    "  sigmav=0.9\n",
    "  sigmau=0.2\n",
    "  nsamp=200\n",
    "\n",
    "  x_org=simulated_datasets_R[[i]]$log_X\n",
    "  y_org=simulated_datasets_R[[i]]$log_y\n",
    "\n",
    "\n",
    "  ########################################\n",
    "  # Model 1 fit the Bayes Linear Model\n",
    "  ########################################\n",
    "\n",
    "  simdt=data.frame(y1=y_org,lnx1=x_org)\n",
    "\n",
    "  B_burnin=1000\n",
    "  B_afterburnin=4000\n",
    "\n",
    "  # B_burnin=2\n",
    "  # B_afterburnin=20\n",
    "\n",
    "  res_Bayelin<-Bayeslinear_NHN_fit(B_burnin,\n",
    "                                   B_afterburnin,\n",
    "                                   simdt,\n",
    "                                   beta0_init = 0,\n",
    "                                   beta_init=beta0,\n",
    "                                   sigu_init=sigmau,\n",
    "                                   sigv_init=sigmav,\n",
    "                                   df_v = 5,\n",
    "                                   S_v =(5+2)*sigmav^2,\n",
    "                                   df_u =5,\n",
    "                                   S_u = (5+2)*sigmau^2)\n",
    "\n",
    "\n",
    "  B=B_burnin+B_afterburnin\n",
    "  res_bayes_lin<-na.omit(res_Bayelin$res[B_burnin+1:B,])\n",
    "\n",
    "  ##############################################\n",
    "  # Model 2\n",
    "  # fit SEM-SFM\n",
    "  # imposing monotonicity restrictions on inputs\n",
    "  ##############################################\n",
    "  #first-step: monotone gam, second-step: fan\n",
    "  dati=data.frame(y=y_org,x=x_org)\n",
    "  semfit<-semsfa(y~pbm(x,mono=\"up\"),sem.method = \"gam.mono\",dati)\n",
    "  sigma_v_semfit=sqrt(semfit$sigma^2/(1+semfit$lambda^2))\n",
    "  sigma_u_semfit=semfit$lambda*sigma_v_semfit\n",
    "\n",
    "  ##############################################\n",
    "  # Model 3\n",
    "  # fit Mon-BART-SFM\n",
    "  # imposing monotonicity restrictions on inputs\n",
    "  ##############################################\n",
    "  #find initial value for sigma_v and sigma_u\n",
    "\n",
    "  fit_sfa <-sfa( y1 ~ lnx1,data = simdt)\n",
    "  gamma <- unname( coef(fit_sfa)[\"gamma\"] )\n",
    "  sigmaSq <- unname( coef(fit_sfa)[\"sigmaSq\"] )\n",
    "  sigmaSqU <- gamma * sigmaSq\n",
    "  sigmaSqV <- ( 1 - gamma ) * sigmaSq\n",
    "  betavec<-coef(fit_sfa)[1:3]\n",
    "  sigma_u<-sqrt(sigmaSqU)\n",
    "  sigma_v<-sqrt(sigmaSqV)\n",
    "\n",
    "\n",
    "\n",
    "  ysnfit<-selm(y_org ~ 1, family=\"SN\")\n",
    "  center_Y <- ysnfit@param$dp[1]\n",
    "\n",
    "  nskip=B_burnin\n",
    "  ndpost=B_afterburnin\n",
    "\n",
    "\n",
    "  fitbartsfm<-monbartsfm(\n",
    "    x.train=as.matrix(x_org),y.train=y_org, x.test=matrix(0.0,0,0),\n",
    "    sigest=sigma_v,\n",
    "    sigdf=3,\n",
    "    sigquant=.95,\n",
    "    sigu_pre_est=sigma_u,\n",
    "    sigquant_u=.95,\n",
    "    k=2.0,\n",
    "    power=.8, base=.25, #regular bart is 2,.95\n",
    "    sigmaf=NA,\n",
    "    lambda=NA,\n",
    "    fmean = center_Y,\n",
    "    #fscale=scale_Y,\n",
    "    ntree=100,\n",
    "    ndpost, nskip,\n",
    "    mgsize=50,\n",
    "    nkeeptrain=ndpost,nkeeptest=ndpost,\n",
    "    nkeeptestmean=ndpost,\n",
    "    nkeeptreedraws=ndpost,\n",
    "    printevery=100\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  fitbartsfm_beta0<-monbartsfm_beta0(\n",
    "    x.train=as.matrix(x_org),y.train=y_org, x.test=matrix(0.0,0,0),\n",
    "    sigest=sigma_v,\n",
    "    sigdf=3,\n",
    "    sigquant=.95,\n",
    "    sigu_pre_est=sigma_u,\n",
    "    sigquant_u=.95,\n",
    "    k=2.0,\n",
    "    power=.8, base=.25, #regular bart is 2,.95\n",
    "    sigmaf=NA,\n",
    "    lambda=NA,\n",
    "    fmean = center_Y,\n",
    "    #fscale=scale_Y,\n",
    "    ntree=100,\n",
    "    ndpost, nskip,\n",
    "    mgsize=50,\n",
    "    nkeeptrain=ndpost,nkeeptest=ndpost,\n",
    "    nkeeptestmean=ndpost,\n",
    "    nkeeptreedraws=ndpost,\n",
    "    printevery=100\n",
    "  )\n",
    "\n",
    "  gtest<-geweke.diag(fitbartsfm$sigma_u)\n",
    "  pval_BART<-1-pnorm(gtest$z)\n",
    "  # pval_BART=0.5\n",
    "  gtest_b0<-geweke.diag(fitbartsfm_beta0$sigma_u)\n",
    "  pval_BART_b0<-1-pnorm(gtest_b0$z)\n",
    "  # pval_BART_b0=0.5\n",
    "  finished <- TRUE #if convergence test is passed, then next iteration\n",
    "\n",
    "  if(pval_BART>0.1&pval_BART_b0>0.1){\n",
    "    finished <- TRUE #if convergence test is passed, then next iteration\n",
    "  }\n",
    "\n",
    "  #######################################\n",
    "  # 1. Compare RMSE and BIAS            #\n",
    "  #######################################\n",
    "\n",
    "  y_tf = exp(beta0)*exp(x_org)^beta1 #((X**w_true)*b_true).numpy() \n",
    "  #############################################################################\n",
    "  #formulas are from Eq. 10 and 11 from                                       #\n",
    "  #Ferrara and Vidoli 2017 Semiparametric Stochastic frontier models          #\n",
    "  #############################################################################\n",
    "    \n",
    "  RMSE_bayeslin           = 0 #mean(((mean(res_Bayelin$res$beta0_post)+mean(res_Bayelin$res$beta_current)*x_org-y_org)/y_org)^2) # I did not calculate the Bayes lin\n",
    "  # e_sem = y_org - (semfit$fitted)\n",
    "  # E_sem_correction = mean(exp(e_sem))\n",
    "\n",
    "  E_sem_correction = exp((sigma_v_semfit**2+sigma_u_semfit**2)/2)    \n",
    "  RMSE_sem         = mean(((exp(semfit$fitted)*E_sem_correction-y_tf)/y_tf)^2)\n",
    "  # e_bartsfm = y_org - (fitbartsfm$yhat.train.mean)\n",
    "  # E_bartsfm_correction = mean(exp(e_bartsfm))\n",
    "  sigv_map = median(fitbartsfm$sigma[(nskip+1):(nskip+ndpost)])\n",
    "  sigu_map = median(fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)])\n",
    "  \n",
    "  E_bartsfm_correction =  exp((sigv_map**2+sigv_map**2)/2)    \n",
    "  RMSE_bartsfm            =mean(((exp(fitbartsfm$yhat.train.mean)*E_bartsfm_correction-y_tf)/y_tf)^2)\n",
    "        \n",
    "  # RMSE_bartsfm_uadj       =mean(((fitbartsfm_uadj$yhat.train.mean-y_org)/y_org)^2)\n",
    "  # e_bartsfm_beta0 = y_org - (fitbartsfm_beta0$yhat.train.mean)\n",
    "  # E_bartsfm_beta0_correction = mean(exp(e_bartsfm_beta0))\n",
    "  sigv_beta0_map = median(fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)])\n",
    "  sigu_beta0_map = median(fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)])\n",
    "\n",
    "  E_bartsfm_beta0_correction = exp((sigv_beta0_map**2+sigu_beta0_map**2)/2)   \n",
    "  RMSE_bartsfm_beta0      =mean(((exp(fitbartsfm_beta0$yhat.train.mean)*E_bartsfm_beta0_correction-y_tf)/y_tf)^2)\n",
    "  # RMSE_bartsfm_beta0_uadj =mean(((fitbartsfm_beta0_uadj$yhat.train.mean-y_org)/y_org)^2)\n",
    "\n",
    "  BIAS_bayeslin           =mean(abs((mean(res_Bayelin$res$beta0_post)+mean(res_Bayelin$res$beta_current)*x_org-y_org)/y_org))\n",
    "  BIAS_sem                =mean(abs((exp(semfit$fitted)*E_sem_correction-y_tf)/y_tf))\n",
    "  BIAS_bartsfm            =mean(abs((exp(fitbartsfm$yhat.train.mean)*E_bartsfm_correction-y_tf)/y_tf))\n",
    "  # BIAS_bartsfm_uadj       =median(((fitbartsfm_uadj$yhat.train.mean-y_org)/y_org))\n",
    "  BIAS_bartsfm_beta0      =median(abs((exp(fitbartsfm_beta0$yhat.train.mean)*E_bartsfm_beta0_correction-y_tf)/y_tf))\n",
    "  # BIAS_bartsfm_beta0_uadj =median(((fitbartsfm_beta0_uadj$yhat.train.mean-y_org)/y_org))\n",
    "\n",
    "  RMSE_res<-c(RMSE_bayeslin,\n",
    "              RMSE_sem,\n",
    "              RMSE_bartsfm,\n",
    "            # RMSE_bartsfm_uadj,\n",
    "              RMSE_bartsfm_beta0\n",
    "  )\n",
    "\n",
    "  BIAS_res <- c(BIAS_bayeslin,\n",
    "                BIAS_sem,\n",
    "                BIAS_bartsfm,\n",
    "                # BIAS_bartsfm_uadj,\n",
    "                BIAS_bartsfm_beta0\n",
    "                # BIAS_bartsfm_beta0_uadj\n",
    "                )\n",
    "\n",
    "  ##############################################################################\n",
    "  # 2. Compare mean bias estimates of sigma_u and sigma_v                           #\n",
    "  ##############################################################################\n",
    "  Bias_sig_v_bayeslin           = abs(median(res_bayes_lin$sigv_post)-sigmav)\n",
    "  Bias_sig_v_sem                = abs(sigma_v_semfit-sigmav)\n",
    "  Bias_sig_v_bartsfm            = abs(median(fitbartsfm$sigma[(nskip+1):(nskip+ndpost)])      -sigmav)\n",
    "  # Bias_sig_v_bartsfm_uadj       = abs(median(fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)]) -sigmav)\n",
    "  Bias_sig_v_bartsfm_beta0      = abs(median(fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)])-sigmav)\n",
    "  # Bias_sig_v_bartsfm_beta0_uadj = abs(median(fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)]) -sigmav)\n",
    "\n",
    "  Bias_sig_u_bayeslin           = abs(median(res_bayes_lin$sigu_post)-sigmau)\n",
    "  Bias_sig_u_sem                = abs(sigma_u_semfit-sigmau)\n",
    "  Bias_sig_u_bartsfm            = abs(median(fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)])     -sigmau)\n",
    "  # Bias_sig_u_bartsfm_uadj       = abs(median(fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)])  -sigmau)\n",
    "  Bias_sig_u_bartsfm_beta0      = abs(median(fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)])  -sigmau)\n",
    "  # Bias_sig_u_bartsfm_beta0_uadj = abs(median(fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)])   -sigmau)\n",
    "\n",
    "  Bias_sig_v_res <- c(\n",
    "      Bias_sig_v_bayeslin      ,\n",
    "      Bias_sig_v_sem           ,\n",
    "      Bias_sig_v_bartsfm       ,\n",
    "      # Bias_sig_v_bartsfm_uadj  ,\n",
    "      Bias_sig_v_bartsfm_beta0\n",
    "      # Bias_sig_v_bartsfm_beta0_uadj\n",
    "    )\n",
    "\n",
    "  Bias_sig_u_res <-\n",
    "    c(Bias_sig_u_bayeslin      ,\n",
    "      Bias_sig_u_sem           ,\n",
    "      Bias_sig_u_bartsfm       ,\n",
    "      # Bias_sig_u_bartsfm_uadj  ,\n",
    "      Bias_sig_u_bartsfm_beta0\n",
    "      # Bias_sig_u_bartsfm_beta0_uadj\n",
    "    )\n",
    "\n",
    "\n",
    "  ##############################################################################\n",
    "  # 3. Compare mean inefficiency scores                                        #\n",
    "  ##############################################################################\n",
    "  #True TEs\n",
    "  res_true<-simdt$y1-(beta0+beta1*simdt$lnx1)\n",
    "  TEvec_true<-sapply(res_true,TE_fun,sigv=sigmav,sigu=sigmau)\n",
    "  mean(TEvec_true)\n",
    "\n",
    "  #Bayes regression TEs\n",
    "  TEvec_bayeslin<-apply(res_bayes_lin,1,function(x){ return(TE_bayes_fun(bayelinres = x,y = simdt$y1,x=simdt$lnx1))})\n",
    "  mean(TEvec_bayeslin)\n",
    "\n",
    "  #TE for sem\n",
    "  res_sem<-simdt$y1-semfit$fitted\n",
    "  TEvec_sem<-sapply(res_sem,TE_fun,sigv=sigma_v_semfit,sigu=sigma_u_semfit)\n",
    "  mean(TEvec_sem)\n",
    "\n",
    "  #TE for bart-sfm\n",
    "  TEvec_bartsfm<-apply(cbind(fitbartsfm$yhat.train,\n",
    "                             fitbartsfm$sigma[(nskip+1):(nskip+ndpost)],\n",
    "                             fitbartsfm$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "                       function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "                                                      sigv_post = y[nsamp+1],\n",
    "                                                      sigu_post = y[nsamp+2],\n",
    "                                                      y_bart = simdt$y1\n",
    "                       ))})\n",
    "\n",
    "  #TE for bart-sfm-uadj\n",
    "  # TEvec_bartsfm_uadj<-apply(cbind(fitbartsfm_uadj$yhat.train,\n",
    "  #                                 fitbartsfm_uadj$sigma[(nskip+1):(nskip+ndpost)],\n",
    "  #                                 fitbartsfm_uadj$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "  #                           function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "  #                                                          sigv_post = y[nsamp+1],\n",
    "  #                                                          sigu_post = y[nsamp+2],\n",
    "  #                                                          y_bart = simdt$y1\n",
    "  #                           ))})\n",
    "\n",
    "  #TE for bart-sfm-beta0\n",
    "  TEvec_bartsfm_beta0<-apply(cbind(fitbartsfm_beta0$yhat.train,\n",
    "                                   fitbartsfm_beta0$sigma[(nskip+1):(nskip+ndpost)],\n",
    "                                   fitbartsfm_beta0$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "                             function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "                                                            sigv_post = y[nsamp+1],\n",
    "                                                            sigu_post = y[nsamp+2],\n",
    "                                                            y_bart = simdt$y1\n",
    "                             ))})\n",
    "\n",
    "\n",
    "  #TE for bart-sfm-beta0-uadj\n",
    "  # TEvec_bartsfm_beta0_uadj<-apply(cbind(fitbartsfm_beta0_uadj$yhat.train,\n",
    "  #                                       fitbartsfm_beta0_uadj$sigma[(nskip+1):(nskip+ndpost)],\n",
    "  #                                       fitbartsfm_beta0_uadj$sigma_u[(nskip+1):(nskip+ndpost)]),1,\n",
    "  #                                 function(y){return(TE_bart_fun(yhat_post = y[1:nsamp],\n",
    "  #                                                                sigv_post = y[nsamp+1],\n",
    "  #                                                                sigu_post = y[nsamp+2],\n",
    "  #                                                                y_bart = simdt$y1\n",
    "  #                                 ))})\n",
    "\n",
    "  TE_bias<-abs(c(\n",
    "    mean(TEvec_bayeslin),\n",
    "    mean(TEvec_sem),\n",
    "    mean(TEvec_bartsfm),\n",
    "    # mean(TEvec_bartsfm_uadj),\n",
    "    mean(TEvec_bartsfm_beta0)\n",
    "    # mean(TEvec_bartsfm_beta0_uadj)\n",
    "  )-mean(TEvec_true))\n",
    "\n",
    "    },\n",
    "  error = function(e) {})\n",
    "}\n",
    "\n",
    "  # TE_bias<-rbind(TE_bias,TE_bias_one)\n",
    "\n",
    "  return(list(RMSE=RMSE_res,\n",
    "              BIAS=BIAS_res,\n",
    "              Bias_sig_v=Bias_sig_v_res,\n",
    "              Bias_sig_u=Bias_sig_u_res,\n",
    "              TE_bias=TE_bias,\n",
    "              simdata=simdt,\n",
    "              sig_v_bart_post=fitbartsfm$sigma,\n",
    "              sig_u_bart_post=fitbartsfm$sigma_u,\n",
    "              sig_v_bart_b0_post=fitbartsfm_beta0$sigma,\n",
    "              sig_u_bart_b0_post=fitbartsfm_beta0$sigma_u\n",
    "              ))\n",
    "\n",
    "}\n",
    "\n",
    "RMSE_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[1]]})))\n",
    "colnames(RMSE_res)<-c(\"RMSE_BayesLin\",\"RMSE_Sem\",\n",
    "                      \"RMSE_Bart\",\n",
    "                      # \"RMSE_Bart_uadj\",\n",
    "                      \"RMSE_Bart_b0\"\n",
    "                      # \"RMSE_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "BIAS_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[2]]})))\n",
    "colnames(BIAS_res)<-c(\"BIAS_BayesLin\",\"BIAS_Sem\",\n",
    "                      \"BIAS_Bart\",\n",
    "                      # \"BIAS_Bart_uadj\",\n",
    "                      \"BIAS_Bart_b0\"\n",
    "                      # \"BIAS_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "Bias_sig_v_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[3]]})))\n",
    "colnames(Bias_sig_v_res)<-c(\"Sigvb_BayesLin\",\"Sigvb_Sem\",\n",
    "                            \"Sigvb_Bart\",\n",
    "                            # \"Sigvb_Bart_uadj\",\n",
    "                            \"Sigvb_Bart_b0\"\n",
    "                            # \"Sigvb_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "Bias_sig_u_res<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[4]]})))\n",
    "colnames(Bias_sig_u_res)<-c(\"Sigub_BayesLin\",\n",
    "                            \"Sigub_Sem\",\n",
    "                            \"Sigub_Bart\",\n",
    "                            # \"Sigub_Bart_uadj\",\n",
    "                            \"Sigub_Bart_b0\"\n",
    "                            # \"Sigub_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "TE_bias<-as.data.frame(do.call(rbind,lapply(res,function(x){x[[5]]})))\n",
    "colnames(TE_bias)<-c(\"TEb_BayesLin\",\"TEb_Sem\",\n",
    "                     \"TEb_Bart\",\n",
    "                     # \"TEb_Bart_uadj\",\n",
    "                     \"TEb_Bart_b0\"\n",
    "                     # \"TEb_Bart_uadj_b0\"\n",
    ")\n",
    "\n",
    "resfin<-list(RMSE=RMSE_res,\n",
    "             BIAS=BIAS_res,\n",
    "             Bias_sigv=Bias_sig_v_res,\n",
    "             Bias_sigu=Bias_sig_u_res,\n",
    "             TE_bias=TE_bias,\n",
    "             res=res)\n",
    "saveRDS(resfin, paste(\"res/linear_case_part\",part,\".rds\",sep = \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10792fc5-ad32-43d0-8efa-1b5ccde47162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R_monbart",
   "language": "R",
   "name": "r4.1.2_monbart"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
